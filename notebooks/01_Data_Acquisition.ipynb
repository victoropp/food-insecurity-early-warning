{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition for Food Insecurity Early Warning\n",
    "\n",
    "**Author**: Victor Collins Oppon\n",
    "\n",
    "**MSc Data Science Dissertation, Middlesex University 2025**\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook downloads and prepares all external data sources:\n",
    "- **IPC data**: FEWSNET IPC assessments (55,129 records, 2021-2024)\n",
    "- **GDELT data**: Global news event database (7.6M articles, 5.2M locations)\n",
    "- **Geographic boundaries**: GADM, Natural Earth, IPC custom boundaries\n",
    "\n",
    "**Runtime**: ~30 minutes (depending on network speed)\n",
    "\n",
    "**Outputs**:\n",
    "- `data/external/ipc/ipcFic_Africa_Current_Only.csv`\n",
    "- `data/external/gdelt/african_gkg_locations_aligned.parquet`\n",
    "- `data/external/shapefiles/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import configuration\n",
    "from config import (\n",
    "    BASE_DIR, EXTERNAL_DATA_DIR, IPC_DIR, GDELT_DIR, \n",
    "    SHAPEFILES_DIR, IPC_FILE, GDELT_LOCATIONS\n",
    ")\n",
    "\n",
    "print(f\"Project root: {BASE_DIR}\")\n",
    "print(f\"External data: {EXTERNAL_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IPC Data Acquisition\n",
    "\n",
    "The Integrated Food Security Phase Classification (IPC) provides ground truth labels for food insecurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if IPC data already exists\n",
    "if IPC_FILE.exists():\n",
    "    print(f\"✓ IPC data already exists: {IPC_FILE}\")\n",
    "    ipc_df = pd.read_csv(IPC_FILE)\n",
    "    print(f\"  Records: {len(ipc_df):,}\")\n",
    "    print(f\"  Countries: {ipc_df['country'].nunique()}\")\n",
    "    print(f\"  Date range: {ipc_df['analysis_date'].min()} to {ipc_df['analysis_date'].max()}\")\n",
    "else:\n",
    "    print(\"IPC data not found.\")\n",
    "    print(\"\")\n",
    "    print(\"MANUAL DOWNLOAD REQUIRED:\")\n",
    "    print(\"1. Visit: https://fews.net/fews-data/335\")\n",
    "    print(\"2. Download: Current IPC classifications for Africa\")\n",
    "    print(f\"3. Save to: {IPC_FILE}\")\n",
    "    print(\"\")\n",
    "    print(\"OR download the pre-processed data archive from Zenodo:\")\n",
    "    print(\"https://doi.org/10.5281/zenodo.XXXXXXX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPC Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IPC_FILE.exists():\n",
    "    # Load and preview IPC data\n",
    "    ipc_df = pd.read_csv(IPC_FILE)\n",
    "    \n",
    "    print(\"IPC Data Sample:\")\n",
    "    display(ipc_df.head())\n",
    "    \n",
    "    print(\"\\nIPC Phase Distribution:\")\n",
    "    print(ipc_df['ipc_phase'].value_counts().sort_index())\n",
    "    \n",
    "    print(\"\\nCountry Coverage:\")\n",
    "    country_counts = ipc_df.groupby('country').size().sort_values(ascending=False)\n",
    "    display(country_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GDELT Data Acquisition\n",
    "\n",
    "GDELT (Global Database of Events, Language, and Tone) provides news event data.\n",
    "\n",
    "**Note**: The full GDELT dataset is 47GB. We use a pre-processed version (613MB) that contains only African location mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GDELT data already exists\n",
    "if GDELT_LOCATIONS.exists():\n",
    "    print(f\"✓ GDELT data already exists: {GDELT_LOCATIONS}\")\n",
    "    \n",
    "    # Load sample\n",
    "    gdelt_df = pd.read_parquet(GDELT_LOCATIONS)\n",
    "    print(f\"  Total location mentions: {len(gdelt_df):,}\")\n",
    "    print(f\"  Unique articles: {gdelt_df['gkg_id'].nunique():,}\")\n",
    "    print(f\"  Date range: {gdelt_df['date'].min()} to {gdelt_df['date'].max()}\")\n",
    "else:\n",
    "    print(\"GDELT data not found.\")\n",
    "    print(\"\")\n",
    "    print(\"The pre-processed GDELT data (613MB) is available in the data archive:\")\n",
    "    print(\"https://doi.org/10.5281/zenodo.XXXXXXX\")\n",
    "    print(\"\")\n",
    "    print(\"To process from raw GDELT:\")\n",
    "    print(\"1. Download GDELT 2.0 GKG files from https://www.gdeltproject.org/\")\n",
    "    print(\"2. Filter for African locations\")\n",
    "    print(\"3. Extract location coordinates\")\n",
    "    print(\"4. Save as parquet for efficiency\")\n",
    "    print(\"\")\n",
    "    print(\"WARNING: Processing raw GDELT takes ~12 hours and requires 100GB+ disk space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDELT Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GDELT_LOCATIONS.exists():\n",
    "    # Load sample\n",
    "    gdelt_sample = pd.read_parquet(GDELT_LOCATIONS, nrows=1000)\n",
    "    \n",
    "    print(\"GDELT Data Sample:\")\n",
    "    display(gdelt_sample.head())\n",
    "    \n",
    "    print(\"\\nColumn Info:\")\n",
    "    print(gdelt_sample.dtypes)\n",
    "    \n",
    "    print(\"\\nTop Countries by Location Mentions:\")\n",
    "    full_df = pd.read_parquet(GDELT_LOCATIONS)\n",
    "    country_mentions = full_df['country'].value_counts().head(10)\n",
    "    display(country_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Geographic Boundaries\n",
    "\n",
    "Download administrative boundaries from GADM and Natural Earth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Download Natural Earth (Country Boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Earth 1:50m Admin 0 (countries)\n",
    "ne_dir = SHAPEFILES_DIR / \"natural_earth\"\n",
    "ne_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ne_file = ne_dir / \"ne_50m_admin_0_countries.shp\"\n",
    "\n",
    "if ne_file.exists():\n",
    "    print(f\"✓ Natural Earth data already exists: {ne_file}\")\n",
    "else:\n",
    "    print(\"Downloading Natural Earth countries (1:50m scale)...\")\n",
    "    \n",
    "    url = \"https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/50m/cultural/ne_50m_admin_0_countries.zip\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "            z.extractall(ne_dir)\n",
    "        \n",
    "        print(f\"✓ Downloaded and extracted to {ne_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading Natural Earth: {e}\")\n",
    "        print(\"Please download manually from:\")\n",
    "        print(\"https://www.naturalearthdata.com/downloads/50m-cultural-vectors/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Download GADM (District Boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GADM administrative boundaries\n",
    "gadm_dir = SHAPEFILES_DIR / \"gadm\"\n",
    "gadm_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List of 18 countries in final analysis\n",
    "countries = ['ZWE', 'SDN', 'COD', 'NGA', 'MOZ', 'MLI', 'KEN', 'ETH', \n",
    "             'MWI', 'SOM', 'TCD', 'NER', 'CMR', 'UGA', 'BDI', 'MDG', 'SSD', 'BFA']\n",
    "\n",
    "print(f\"Downloading GADM data for {len(countries)} countries...\")\n",
    "print(\"This may take 10-15 minutes depending on network speed.\")\n",
    "print(\"\")\n",
    "\n",
    "for country_iso in tqdm(countries, desc=\"Countries\"):\n",
    "    country_file = gadm_dir / f\"gadm41_{country_iso}_2.shp\"\n",
    "    \n",
    "    if country_file.exists():\n",
    "        continue\n",
    "    \n",
    "    # Download GADM level 2 (districts)\n",
    "    url = f\"https://geodata.ucdavis.edu/gadm/gadm4.1/shp/gadm41_{country_iso}_shp.zip\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=60)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "                # Extract only level 2 files\n",
    "                for file in z.namelist():\n",
    "                    if '_2.' in file:\n",
    "                        z.extract(file, gadm_dir)\n",
    "        \n",
    "        time.sleep(1)  # Be nice to server\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError downloading {country_iso}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n✓ GADM download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Verify Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count shapefiles\n",
    "ne_shapefiles = list((SHAPEFILES_DIR / \"natural_earth\").glob(\"*.shp\"))\n",
    "gadm_shapefiles = list((SHAPEFILES_DIR / \"gadm\").glob(\"*_2.shp\"))\n",
    "\n",
    "print(f\"Natural Earth shapefiles: {len(ne_shapefiles)}\")\n",
    "print(f\"GADM shapefiles (level 2): {len(gadm_shapefiles)}\")\n",
    "\n",
    "if ne_shapefiles:\n",
    "    # Test loading one\n",
    "    ne_gdf = gpd.read_file(ne_shapefiles[0])\n",
    "    print(f\"\\nNatural Earth sample: {len(ne_gdf)} countries\")\n",
    "    \n",
    "if gadm_shapefiles:\n",
    "    # Test loading one\n",
    "    test_file = gadm_shapefiles[0]\n",
    "    test_gdf = gpd.read_file(test_file)\n",
    "    print(f\"\\nGADM sample ({test_file.name}): {len(test_gdf)} districts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATA ACQUISITION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check each data source\n",
    "data_sources = {\n",
    "    'IPC data': IPC_FILE,\n",
    "    'GDELT locations': GDELT_LOCATIONS,\n",
    "    'Natural Earth': SHAPEFILES_DIR / \"natural_earth\" / \"ne_50m_admin_0_countries.shp\",\n",
    "    'GADM (sample)': SHAPEFILES_DIR / \"gadm\" / \"gadm41_ZWE_2.shp\"\n",
    "}\n",
    "\n",
    "for name, path in data_sources.items():\n",
    "    if path.exists():\n",
    "        size_mb = path.stat().st_size / (1024**2)\n",
    "        print(f\"✓ {name:20s}: {size_mb:>8.1f} MB\")\n",
    "    else:\n",
    "        print(f\"✗ {name:20s}: NOT FOUND\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"Next step: 02_Data_Processing.ipynb\")\n",
    "print(\"This notebook aggregates GDELT articles and locations to IPC districts.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
