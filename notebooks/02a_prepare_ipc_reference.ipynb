{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-header",
   "metadata": {},
   "source": [
    "# IPC Reference Preparation - District Level\n",
    "\n",
    "**Script**: `scripts/02_data_processing/01_prepare_ipc_reference.py`\n",
    "\n",
    "**Author**: Victor Collins Oppon, MSc Data Science, Middlesex University 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Creates a standardized IPC reference dataset with proper district extraction.\n",
    "\n",
    "**KEY CORRECTION**:\n",
    "- Uses `geographic_unit_full_name` as the unique geographic identifier (NOT `geographic_unit_name`)\n",
    "- Extracts district name from the hierarchical full_name structure\n",
    "- Each `(geographic_unit_full_name, period)` is one unique observation\n",
    "\n",
    "**Runtime**: ~5 minutes\n",
    "\n",
    "**Input**: `data/external/ipc/ipcFic_Africa_Current_Only.csv` (55,129 records)\n",
    "\n",
    "**Output**: `data/district_level/ipc_reference.parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "from config import BASE_DIR\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(str(BASE_DIR.parent.parent.parent))\n",
    "IPC_FILE = BASE_DIR / 'FEWSNET IPC' / 'ipcFic_Africa_Current_Only.csv'\n",
    "\n",
    "# Output to district_level subfolder for traceability\n",
    "OUTPUT_DIR = BASE_DIR / 'data' / 'district_level'\n",
    "OUTPUT_FILE = OUTPUT_DIR / 'ipc_reference.parquet'\n",
    "OUTPUT_CSV = OUTPUT_DIR / 'ipc_reference.csv'\n",
    "\n",
    "print(f\"Input file: {IPC_FILE}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fips-mapping-header",
   "metadata": {},
   "source": [
    "## FIPS Country Code Mapping\n",
    "\n",
    "GDELT uses FIPS codes, so we need to map IPC countries to FIPS for downstream matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fips-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIPS to Country name mapping (GDELT uses FIPS codes)\n",
    "FIPS_TO_COUNTRY = {\n",
    "    'AO': 'Angola',\n",
    "    'UV': 'Burkina Faso',\n",
    "    'BY': 'Burundi',\n",
    "    'CM': 'Cameroon',\n",
    "    'CT': 'Central African Republic',\n",
    "    'CD': 'Chad',\n",
    "    'CG': 'Democratic Republic of the Congo',\n",
    "    'ET': 'Ethiopia',\n",
    "    'KE': 'Kenya',\n",
    "    'LT': 'Lesotho',\n",
    "    'MA': 'Madagascar',\n",
    "    'MI': 'Malawi',\n",
    "    'ML': 'Mali',\n",
    "    'MR': 'Mauritania',\n",
    "    'MZ': 'Mozambique',\n",
    "    'NG': 'Niger',\n",
    "    'NI': 'Nigeria',\n",
    "    'RW': 'Rwanda',\n",
    "    'SO': 'Somalia',\n",
    "    'OD': 'South Sudan',\n",
    "    'SU': 'Sudan',\n",
    "    'TO': 'Togo',\n",
    "    'UG': 'Uganda',\n",
    "    'ZI': 'Zimbabwe',\n",
    "}\n",
    "\n",
    "# Country names for parsing (including variations)\n",
    "COUNTRY_NAMES = [\n",
    "    'Ethiopia', 'Kenya', 'Nigeria', 'Democratic Republic of the Congo',\n",
    "    'Madagascar', 'Uganda', 'Somalia', 'Sudan', 'South Sudan', 'Chad',\n",
    "    'Mali', 'Niger', 'Burkina Faso', 'Cameroon', 'Mozambique', 'Zimbabwe',\n",
    "    'Malawi', 'Angola', 'Burundi', 'Lesotho', 'Mauritania', 'Rwanda', 'Togo',\n",
    "    'Central African Republic', 'Congo', 'The Democratic Republic of the'\n",
    "]\n",
    "\n",
    "print(f\"FIPS mappings: {len(FIPS_TO_COUNTRY)} countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functions-header",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Functions for text normalization and district extraction from hierarchical IPC names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text for matching: lowercase, strip, remove special chars\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = str(text).lower().strip()\n",
    "    # Remove special characters but keep spaces\n",
    "    text = ''.join(c if c.isalnum() or c.isspace() else ' ' for c in text)\n",
    "    # Collapse multiple spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "print(\"Test normalization:\")\n",
    "print(f\"  'Kasaï Central' → '{normalize_text('Kasaï Central')}'\")\n",
    "print(f\"  'Nord-Kivu' → '{normalize_text('Nord-Kivu')}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-district-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_district_from_full_name(full_name, unit_name, country):\n",
    "    \"\"\"\n",
    "    Extract district name from geographic_unit_full_name.\n",
    "    \n",
    "    Structure varies by country but generally:\n",
    "    - Admin records: [District], [Zone], [Region], [Country]\n",
    "    - LHZ records: [LHZ_name], [District], [Zone], [Country]\n",
    "    \n",
    "    The key insight: geographic_unit_full_name contains the district,\n",
    "    even for LHZ-labeled records.\n",
    "    \"\"\"\n",
    "    if pd.isna(full_name):\n",
    "        return unit_name if pd.notna(unit_name) else ''\n",
    "    \n",
    "    full_name = str(full_name).strip()\n",
    "    unit_name = str(unit_name).strip() if pd.notna(unit_name) else ''\n",
    "    \n",
    "    # Split by comma\n",
    "    parts = [p.strip() for p in full_name.split(',')]\n",
    "    \n",
    "    # Remove empty parts\n",
    "    parts = [p for p in parts if p]\n",
    "    \n",
    "    if len(parts) <= 1:\n",
    "        return unit_name if unit_name else full_name\n",
    "    \n",
    "    # Remove country names from the end\n",
    "    while parts and parts[-1] in COUNTRY_NAMES:\n",
    "        parts = parts[:-1]\n",
    "    \n",
    "    if not parts:\n",
    "        return unit_name if unit_name else full_name\n",
    "    \n",
    "    # Determine if this is an LHZ or admin record\n",
    "    word_count = len(unit_name.split()) if unit_name else 0\n",
    "    \n",
    "    if word_count >= 4:\n",
    "        # LHZ record: unit_name is LHZ, district follows\n",
    "        # Try to find where unit_name ends in full_name\n",
    "        if full_name.startswith(unit_name):\n",
    "            # Remove the LHZ name and get the next part\n",
    "            remainder = full_name[len(unit_name):].lstrip(', ')\n",
    "            remainder_parts = [p.strip() for p in remainder.split(',')]\n",
    "            remainder_parts = [p for p in remainder_parts if p and p not in COUNTRY_NAMES]\n",
    "            if remainder_parts:\n",
    "                return remainder_parts[0]\n",
    "        \n",
    "        # Fallback: district is typically 2nd from last (before region, country)\n",
    "        if len(parts) >= 2:\n",
    "            return parts[-2] if parts[-2] not in COUNTRY_NAMES else parts[-1]\n",
    "    else:\n",
    "        # Admin record: unit_name IS the district\n",
    "        return unit_name if unit_name else parts[0]\n",
    "    \n",
    "    return unit_name if unit_name else parts[0]\n",
    "\n",
    "print(\"extract_district_from_full_name defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-region-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region_from_full_name(full_name):\n",
    "    \"\"\"Extract region/province from full_name (typically 2nd-to-last before country)\"\"\"\n",
    "    if pd.isna(full_name):\n",
    "        return ''\n",
    "    \n",
    "    parts = [p.strip() for p in str(full_name).split(',')]\n",
    "    parts = [p for p in parts if p]\n",
    "    \n",
    "    # Remove country names\n",
    "    while parts and parts[-1] in COUNTRY_NAMES:\n",
    "        parts = parts[:-1]\n",
    "    \n",
    "    if len(parts) >= 2:\n",
    "        return parts[-1]  # Region is last after removing country\n",
    "    \n",
    "    return ''\n",
    "\n",
    "print(\"extract_region_from_full_name defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processing-header",
   "metadata": {},
   "source": [
    "## Main Processing\n",
    "\n",
    "Load, process, and prepare the IPC reference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"IPC Reference Preparation - DISTRICT LEVEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load IPC data\n",
    "print(\"\\n1. Loading IPC data...\")\n",
    "ipc = pd.read_csv(IPC_FILE)\n",
    "print(f\"   Loaded {len(ipc):,} IPC records\")\n",
    "\n",
    "# Show sample\n",
    "ipc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert-dates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates\n",
    "print(\"\\n2. Converting dates...\")\n",
    "ipc['projection_start'] = pd.to_datetime(ipc['projection_start'])\n",
    "ipc['projection_end'] = pd.to_datetime(ipc['projection_end'])\n",
    "ipc['reporting_date'] = pd.to_datetime(ipc['reporting_date'])\n",
    "\n",
    "print(f\"   Date range: {ipc['projection_start'].min()} to {ipc['projection_end'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add-fips",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add country FIPS codes for easier GDELT matching\n",
    "print(\"\\n3. Adding FIPS country codes...\")\n",
    "country_to_fips = {v: k for k, v in FIPS_TO_COUNTRY.items()}\n",
    "ipc['fips_code'] = ipc['country'].map(country_to_fips)\n",
    "\n",
    "# Calculate period length in days\n",
    "ipc['period_length_days'] = (ipc['projection_end'] - ipc['projection_start']).dt.days + 1\n",
    "\n",
    "print(f\"   Added FIPS codes for {ipc['fips_code'].notna().sum():,} records\")\n",
    "print(f\"\\n   Sample FIPS mappings:\")\n",
    "print(ipc[['country', 'fips_code']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-districts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Extract district from full_name\n",
    "print(\"\\n4. Extracting district names from geographic_unit_full_name...\")\n",
    "ipc['district'] = ipc.apply(\n",
    "    lambda row: extract_district_from_full_name(\n",
    "        row['geographic_unit_full_name'],\n",
    "        row['geographic_unit_name'],\n",
    "        row['country']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Extract region\n",
    "ipc['region'] = ipc['geographic_unit_full_name'].apply(extract_region_from_full_name)\n",
    "\n",
    "print(f\"   Extracted {ipc['district'].notna().sum():,} district names\")\n",
    "print(f\"   Unique districts: {ipc['district'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize-names",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize for matching\n",
    "print(\"\\n5. Normalizing geographic names for matching...\")\n",
    "ipc['district_normalized'] = ipc['district'].apply(normalize_text)\n",
    "ipc['full_name_normalized'] = ipc['geographic_unit_full_name'].apply(normalize_text)\n",
    "ipc['unit_name_normalized'] = ipc['geographic_unit_name'].apply(normalize_text)\n",
    "\n",
    "print(\"   Normalized all geographic fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary classification\n",
    "print(\"\\n6. Creating binary IPC classification...\")\n",
    "ipc['ipc_binary_crisis'] = (ipc['value'] >= 3.0).astype(int)\n",
    "\n",
    "print(\"\\n   IPC Binary Crisis distribution:\")\n",
    "print(ipc['ipc_binary_crisis'].value_counts())\n",
    "\n",
    "print(\"\\n   IPC Value distribution:\")\n",
    "print(ipc['value'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-obs-id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique observation identifier\n",
    "# Each (geographic_unit_full_name, period) is one observation\n",
    "ipc['observation_id'] = (\n",
    "    ipc['geographic_unit_full_name'].astype(str) + '_' +\n",
    "    ipc['projection_start'].astype(str)\n",
    ")\n",
    "\n",
    "# Check for duplicates\n",
    "n_duplicates = len(ipc) - ipc['observation_id'].nunique()\n",
    "print(f\"\\n   Duplicate (full_name, period) combinations: {n_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and rename columns for clarity\n",
    "print(\"\\n7. Selecting columns...\")\n",
    "ipc_reference = ipc[[\n",
    "    'id',  # Original IPC ID\n",
    "    'country', 'country_code', 'fips_code',\n",
    "    # Geographic hierarchy\n",
    "    'geographic_unit_name',  # Original unit name (may be LHZ or admin)\n",
    "    'geographic_unit_full_name',  # FULL hierarchical name (THE KEY IDENTIFIER)\n",
    "    'district',  # Extracted district name\n",
    "    'region',  # Extracted region/province\n",
    "    # Normalized versions for matching\n",
    "    'district_normalized',\n",
    "    'full_name_normalized',\n",
    "    'unit_name_normalized',\n",
    "    # FEWS NET metadata\n",
    "    'fewsnet_region', 'geographic_group',\n",
    "    # Time period\n",
    "    'projection_start', 'projection_end', 'period_length_days',\n",
    "    # IPC values\n",
    "    'value', 'description', 'ipc_binary_crisis',\n",
    "    'is_allowing_for_assistance',\n",
    "    # Additional metadata\n",
    "    'scenario', 'scenario_name', 'classification_scale',\n",
    "    'reporting_date', 'collection_schedule', 'collection_status',\n",
    "    'source_organization', 'source_document',\n",
    "    # Observation ID\n",
    "    'observation_id'\n",
    "]].copy()\n",
    "\n",
    "# Rename for clarity in downstream scripts\n",
    "ipc_reference = ipc_reference.rename(columns={\n",
    "    'id': 'ipc_id',\n",
    "    'value': 'ipc_value',\n",
    "    'description': 'ipc_description'\n",
    "})\n",
    "\n",
    "# Sort by country and date\n",
    "ipc_reference = ipc_reference.sort_values(\n",
    "    ['country', 'district', 'projection_start']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"   Selected {len(ipc_reference.columns)} columns\")\n",
    "print(f\"   Sorted by country, district, date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"IPC Reference Summary - DISTRICT LEVEL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal records: {len(ipc_reference):,}\")\n",
    "print(f\"Unique observations (full_name, period): {ipc_reference['observation_id'].nunique():,}\")\n",
    "print(f\"Date range: {ipc_reference['projection_start'].min()} to {ipc_reference['projection_end'].max()}\")\n",
    "print(f\"Countries: {ipc_reference['country'].nunique()}\")\n",
    "print(f\"Unique geographic_unit_full_name: {ipc_reference['geographic_unit_full_name'].nunique():,}\")\n",
    "print(f\"Unique districts (extracted): {ipc_reference['district'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nDistricts per country:\")\n",
    "district_counts = ipc_reference.groupby('country')['district'].nunique().sort_values(ascending=False)\n",
    "for country, count in district_counts.items():\n",
    "    records = len(ipc_reference[ipc_reference['country'] == country])\n",
    "    print(f\"   {country}: {count} districts, {records:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of final dataset\n",
    "print(\"\\nSample of IPC reference:\")\n",
    "ipc_reference[['ipc_id', 'country', 'district', 'ipc_value', 'projection_start']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verification-header",
   "metadata": {},
   "source": [
    "## District Extraction Verification\n",
    "\n",
    "Verify that district extraction worked correctly by showing examples from different countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"District Extraction Verification\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sample from different countries\n",
    "for country in ['Ethiopia', 'Nigeria', 'Kenya', 'Democratic Republic of the Congo']:\n",
    "    print(f\"\\n{country} samples:\")\n",
    "    sample = ipc_reference[ipc_reference['country'] == country].head(3)\n",
    "    for _, row in sample.iterrows():\n",
    "        print(f\"   Unit: {row['geographic_unit_name'][:50]}...\")\n",
    "        print(f\"   Full: {row['geographic_unit_full_name'][:60]}...\")\n",
    "        print(f\"   District: {row['district']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## Save Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "print(f\"\\n8. Saving to {OUTPUT_FILE}...\")\n",
    "ipc_reference.to_parquet(OUTPUT_FILE, index=False)\n",
    "print(\"   [OK] Parquet saved\")\n",
    "\n",
    "# Also save as CSV for inspection\n",
    "print(f\"\\n9. Saving CSV to {OUTPUT_CSV}...\")\n",
    "ipc_reference.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"   [OK] CSV saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"IPC Reference Preparation Complete!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nKey columns for downstream scripts:\")\n",
    "print(\"   - ipc_id: Unique IPC assessment ID\")\n",
    "print(\"   - geographic_unit_full_name: THE PRIMARY GEOGRAPHIC IDENTIFIER\")\n",
    "print(\"   - district: Extracted district name for spatial matching\")\n",
    "print(\"   - district_normalized: Normalized district for fuzzy matching\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
