{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fca1dc",
   "metadata": {},
   "source": [
    "# Stage 1: Publication-Grade Visualizations and Analysis - DISTRICT LEVEL\n",
    "\n",
    "**Script**: `scripts/03_stage1_baseline/08_stage1_visualizations.py`\n",
    "\n",
    "**Author**: Victor Collins Oppon, MSc Data Science, Middlesex University 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Comprehensive visual analysis of AR baseline performance with storytelling approach.\n",
    "Uses official IPC color schemes and cartographic maps.\n",
    "\n",
    "**KEY VISUALIZATIONS**:\n",
    "1. Performance overview across horizons\n",
    "2. Confusion matrices\n",
    "3. Model coefficients (Lt vs Ls)\n",
    "4. Spatial CV stability\n",
    "5. AR failures temporal distribution\n",
    "6. Performance by country\n",
    "7. Feature space distribution\n",
    "8. Prediction calibration\n",
    "9. ROC and PR curves\n",
    "10. ROC curves by fold\n",
    "11. Choropleth maps\n",
    "12. Executive summary infographic\n",
    "\n",
    "**Runtime**: ~30 minutes\n",
    "\n",
    "**Input**: `results/district_level/stage1_baseline/`\n",
    "\n",
    "**Output**: `figures/stage1_district_level/` (15+ publication-quality figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87139e90",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a04ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stage 1: Publication-Grade Visualizations and Analysis - DISTRICT LEVEL\n",
    "Comprehensive visual analysis of AR baseline performance with storytelling approach\n",
    "Uses official IPC color schemes and cartographic maps\n",
    "\n",
    "Author: Victor Collins Oppon\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directory to path for config import\n",
    "sys.path.append(str(Path(__file__).parent.parent))\n",
    "\n",
    "# Import from config\n",
    "from config import (\n",
    "    BASE_DIR,\n",
    "    STAGE1_DATA_DIR,\n",
    "    STAGE1_RESULTS_DIR,\n",
    "    STAGE2_FEATURES_DIR,\n",
    "    STAGE2_MODELS_DIR,\n",
    "    FIGURES_DIR,\n",
    "    RANDOM_STATE\n",
    ")\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import mapping libraries\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Import sklearn metrics for ROC/PR curves\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "# Paths - DISTRICT LEVEL\n",
    "# BASE_DIR imported from config\n",
    "RESULTS_DIR = BASE_DIR / 'results' / 'district_level' / 'stage1_baseline'\n",
    "FIGURES_DIR = BASE_DIR / 'figures' / 'stage1_district_level'\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Official IPC Color Scheme\n",
    "IPC_COLORS = {\n",
    "    1: '#6ABD45',  # Minimal - Green\n",
    "    2: '#F9E814',  # Stressed - Yellow\n",
    "    3: '#F58220',  # Crisis - Orange\n",
    "    4: '#E31E24',  # Emergency - Red\n",
    "    5: '#6D071A'   # Famine - Dark Red/Maroon\n",
    "}\n",
    "\n",
    "# Performance color scheme (monochromatic blues for bars)\n",
    "PERFORMANCE_COLORS = {\n",
    "    'primary': '#1f77b4',      # Blue\n",
    "    'secondary': '#aec7e8',    # Light blue\n",
    "    'tertiary': '#4292c6',     # Medium blue\n",
    "    'quaternary': '#08519c'    # Dark blue\n",
    "}\n",
    "\n",
    "# Set publication-quality style\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "def load_data():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd290e8",
   "metadata": {},
   "source": [
    "## Load Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"Load all prediction results and metrics - DISTRICT LEVEL\"\"\"\n",
    "    print(\"Loading DISTRICT-LEVEL prediction results...\")\n",
    "\n",
    "    data = {}\n",
    "    horizons = []\n",
    "\n",
    "    # Detect available horizons dynamically\n",
    "    for horizon in [4, 8, 12]:\n",
    "        pred_file = RESULTS_DIR / f'predictions_h{horizon}_district_averaged.parquet'\n",
    "        if pred_file.exists():\n",
    "            horizons.append(horizon)\n",
    "            data[f'h{horizon}'] = pd.read_parquet(pred_file)\n",
    "\n",
    "            # Load AR failures\n",
    "            failures_file = RESULTS_DIR / f'ar_failures_h{horizon}_district_optimal.csv'\n",
    "            if failures_file.exists():\n",
    "                data[f'failures_h{horizon}'] = pd.read_csv(failures_file)\n",
    "            else:\n",
    "                data[f'failures_h{horizon}'] = pd.DataFrame()\n",
    "\n",
    "    # Load metrics\n",
    "    metrics_file = RESULTS_DIR / 'performance_metrics_district.csv'\n",
    "    if metrics_file.exists():\n",
    "        data['metrics'] = pd.read_csv(metrics_file)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Metrics file not found: {metrics_file}\")\n",
    "\n",
    "    # Load coefficients\n",
    "    coef_file = RESULTS_DIR / 'model_coefficients_district.csv'\n",
    "    if coef_file.exists():\n",
    "        data['coefficients'] = pd.read_csv(coef_file)\n",
    "    else:\n",
    "        data['coefficients'] = pd.DataFrame()\n",
    "\n",
    "    data['horizons'] = horizons\n",
    "\n",
    "    print(f\"   Loaded predictions for {len(horizons)} horizons\")\n",
    "    for h in horizons:\n",
    "        print(f\"   h={h}: {len(data[f'h{h}']):,} observations\")\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea4b4a",
   "metadata": {},
   "source": [
    "## Figure 1: Performance Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 1: Performance Metrics Across Horizons\n",
    "    Story: How well does the AR baseline perform at different prediction horizons?\n",
    "    \"\"\"\n",
    "    print(\"\\n1. Creating performance overview...\")\n",
    "\n",
    "    # Get overall metrics (where fold is NaN)\n",
    "    metrics = data['metrics'][data['metrics']['fold'].isna()].copy()\n",
    "    metrics = metrics.sort_values('horizon')\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle('Stage 1 Baseline: Performance Across Prediction Horizons\\n' +\n",
    "                 'Spatio-Temporal Autoregressive Model (Lt + Ls) - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "\n",
    "    # Filter metrics to available horizons\n",
    "    metrics = metrics[metrics['horizon'].isin(horizons)]\n",
    "\n",
    "    # 1. Accuracy metrics\n",
    "    ax = axes[0, 0]\n",
    "    x = np.arange(len(horizons))\n",
    "    width = 0.25\n",
    "\n",
    "    accuracy_vals = [metrics[metrics['horizon'] == h]['accuracy'].values[0] for h in horizons]\n",
    "    precision_vals = [metrics[metrics['horizon'] == h]['precision'].values[0] for h in horizons]\n",
    "    recall_vals = [metrics[metrics['horizon'] == h]['recall'].values[0] for h in horizons]\n",
    "\n",
    "    ax.bar(x - width, accuracy_vals, width,\n",
    "           label='Accuracy', color=PERFORMANCE_COLORS['primary'], alpha=0.8)\n",
    "    ax.bar(x, precision_vals, width,\n",
    "           label='Precision', color=PERFORMANCE_COLORS['secondary'], alpha=0.8)\n",
    "    ax.bar(x + width, recall_vals, width,\n",
    "           label='Recall', color=PERFORMANCE_COLORS['tertiary'], alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel('Prediction Horizon (months)')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('(A) Classification Performance', fontweight='bold', loc='left')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{h}' for h in horizons])\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.legend(frameon=True, loc='lower left')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add value labels\n",
    "    for i, h in enumerate(horizons):\n",
    "        ax.text(i - width, accuracy_vals[i] + 0.02, f\"{accuracy_vals[i]:.2f}\",\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "        ax.text(i, precision_vals[i] + 0.02, f\"{precision_vals[i]:.2f}\",\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "        ax.text(i + width, recall_vals[i] + 0.02, f\"{recall_vals[i]:.2f}\",\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    # 2. F1 and AUC scores\n",
    "    ax = axes[0, 1]\n",
    "    x = np.arange(len(horizons))\n",
    "    width = 0.35\n",
    "\n",
    "    f1_vals = [metrics[metrics['horizon'] == h]['f1'].values[0] for h in horizons]\n",
    "    auc_vals = [metrics[metrics['horizon'] == h]['auc_roc'].values[0] for h in horizons]\n",
    "\n",
    "    ax.bar(x - width/2, f1_vals, width,\n",
    "           label='F1 Score', color=PERFORMANCE_COLORS['primary'], alpha=0.8)\n",
    "    ax.bar(x + width/2, auc_vals, width,\n",
    "           label='AUC-ROC', color=PERFORMANCE_COLORS['quaternary'], alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel('Prediction Horizon (months)')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('(B) Composite Metrics', fontweight='bold', loc='left')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{h}' for h in horizons])\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.legend(frameon=True)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add value labels\n",
    "    for i, h in enumerate(horizons):\n",
    "        ax.text(i - width/2, f1_vals[i] + 0.02, f\"{f1_vals[i]:.2f}\",\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "        ax.text(i + width/2, auc_vals[i] + 0.02, f\"{auc_vals[i]:.2f}\",\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    # 3. Sample sizes and class distribution\n",
    "    ax = axes[1, 0]\n",
    "    x = np.arange(len(horizons))\n",
    "    width = 0.35\n",
    "\n",
    "    no_crisis_vals = [metrics[metrics['horizon'] == h]['n_no_crisis'].values[0] for h in horizons]\n",
    "    crisis_vals = [metrics[metrics['horizon'] == h]['n_crisis'].values[0] for h in horizons]\n",
    "\n",
    "    ax.bar(x - width/2, no_crisis_vals, width,\n",
    "           label='No Crisis (IPC<3)', color='#6ABD45', alpha=0.7)\n",
    "    ax.bar(x + width/2, crisis_vals, width,\n",
    "           label='Crisis (IPC>=3)', color='#F58220', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Prediction Horizon (months)')\n",
    "    ax.set_ylabel('Number of Observations')\n",
    "    ax.set_title('(C) Dataset Composition', fontweight='bold', loc='left')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{h}' for h in horizons])\n",
    "    ax.legend(frameon=True)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add percentage labels\n",
    "    for i, h in enumerate(horizons):\n",
    "        row = metrics[metrics['horizon'] == h].iloc[0]\n",
    "        total = row['n_samples']\n",
    "        crisis_pct = row['n_crisis'] / total * 100 if total > 0 else 0\n",
    "        ax.text(i + width/2, crisis_vals[i] + max(crisis_vals)*0.02, f\"{crisis_pct:.1f}%\",\n",
    "                ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "    # 4. AR Failures (critical for Stage 2)\n",
    "    ax = axes[1, 1]\n",
    "    x = np.arange(len(horizons))\n",
    "\n",
    "    # Calculate AR failures from confusion matrix\n",
    "    ar_failures = [metrics[metrics['horizon'] == h]['false_negatives'].values[0] for h in horizons]\n",
    "    total_crisis = [metrics[metrics['horizon'] == h]['n_crisis'].values[0] for h in horizons]\n",
    "    failure_rate = [(ar/tc * 100) if tc > 0 else 0 for ar, tc in zip(ar_failures, total_crisis)]\n",
    "\n",
    "    bars = ax.bar(x, failure_rate, color='#E31E24', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "    ax.set_xlabel('Prediction Horizon (months)')\n",
    "    ax.set_ylabel('AR Failure Rate (%)')\n",
    "    ax.set_title('(D) Missed Crisis Events (AR Failures)', fontweight='bold', loc='left')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{h}' for h in horizons])\n",
    "    ax.set_ylim(0, max(failure_rate) * 1.3 if failure_rate else 25)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add value labels\n",
    "    for i, (rate, count) in enumerate(zip(failure_rate, ar_failures)):\n",
    "        ax.text(i, rate + 0.5, f\"{rate:.1f}%\\n({int(count)} events)\",\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "    # Add horizontal line at 20% threshold\n",
    "    ax.axhline(y=20, color='red', linestyle='--', linewidth=1, alpha=0.5, label='20% threshold')\n",
    "    ax.legend(frameon=True, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '01_performance_overview.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5822d",
   "metadata": {},
   "source": [
    "## Figure 2: Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d898dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 2: Confusion Matrices for Each Horizon\n",
    "    Story: Where does the model succeed and fail?\n",
    "    \"\"\"\n",
    "    print(\"\\n2. Creating confusion matrices...\")\n",
    "\n",
    "    metrics = data['metrics'][data['metrics']['fold'].isna()].copy()\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(horizons), figsize=(5*len(horizons), 4))\n",
    "    if len(horizons) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle('Stage 1 Baseline: Confusion Matrices by Prediction Horizon\\n' +\n",
    "                 'Actual vs Predicted Crisis Onset (IPC >= 3) - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    for idx, horizon in enumerate(horizons):\n",
    "        ax = axes[idx]\n",
    "        row = metrics[metrics['horizon'] == horizon].iloc[0]\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cm = np.array([\n",
    "            [row['true_negatives'], row['false_positives']],\n",
    "            [row['false_negatives'], row['true_positives']]\n",
    "        ])\n",
    "\n",
    "        # Normalize for percentage display\n",
    "        cm_pct = cm / cm.sum() * 100\n",
    "\n",
    "        # Create heatmap\n",
    "        sns.heatmap(cm, annot=False, fmt='d', cmap='Blues',\n",
    "                    cbar=False, ax=ax, linewidths=2, linecolor='black')\n",
    "\n",
    "        # Add custom annotations with counts and percentages\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                count = cm[i, j]\n",
    "                pct = cm_pct[i, j]\n",
    "                text = f'{int(count):,}\\n({pct:.1f}%)'\n",
    "                color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
    "                ax.text(j + 0.5, i + 0.5, text,\n",
    "                       ha='center', va='center', fontsize=11,\n",
    "                       color=color, fontweight='bold')\n",
    "\n",
    "        ax.set_xlabel('Predicted Label', fontweight='bold')\n",
    "        ax.set_ylabel('True Label', fontweight='bold')\n",
    "        ax.set_title(f'h={horizon} months\\n' +\n",
    "                     f'Accuracy: {row[\"accuracy\"]:.3f} | Recall: {row[\"recall\"]:.3f}',\n",
    "                     fontweight='bold')\n",
    "        ax.set_xticklabels(['No Crisis\\n(0)', 'Crisis\\n(1)'])\n",
    "        ax.set_yticklabels(['No Crisis\\n(0)', 'Crisis\\n(1)'], rotation=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '02_confusion_matrices.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63edbe06",
   "metadata": {},
   "source": [
    "## Figure 3: Model Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 3: Model Coefficients Across Horizons\n",
    "    Story: What drives crisis predictions? Temporal vs Spatial features\n",
    "    \"\"\"\n",
    "    print(\"\\n3. Creating coefficient analysis...\")\n",
    "\n",
    "    if data['coefficients'].empty:\n",
    "        print(\"   [WARNING] No coefficient data available, skipping...\")\n",
    "        return\n",
    "\n",
    "    coefs = data['coefficients'].copy()\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    # Average coefficients across folds\n",
    "    avg_coefs = coefs.groupby('horizon').agg({\n",
    "        'intercept': ['mean', 'std'],\n",
    "        'coef_Lt': ['mean', 'std'],\n",
    "        'coef_Ls': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "\n",
    "    # Filter to available horizons\n",
    "    avg_coefs = avg_coefs[avg_coefs['horizon'].isin(horizons)]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle('Stage 1 Baseline: Logistic Regression Coefficients\\n' +\n",
    "                 'Feature Importance for Crisis Prediction - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    # 1. Coefficient values with error bars\n",
    "    ax = axes[0]\n",
    "    x = np.arange(len(avg_coefs))\n",
    "    width = 0.35\n",
    "\n",
    "    lt_means = avg_coefs[('coef_Lt', 'mean')].values\n",
    "    lt_stds = avg_coefs[('coef_Lt', 'std')].values\n",
    "    ls_means = avg_coefs[('coef_Ls', 'mean')].values\n",
    "    ls_stds = avg_coefs[('coef_Ls', 'std')].values\n",
    "\n",
    "    ax.bar(x - width/2, lt_means, width, yerr=lt_stds,\n",
    "           label='Lt (Temporal Lag)', color=PERFORMANCE_COLORS['primary'],\n",
    "           alpha=0.8, capsize=5, error_kw={'linewidth': 2})\n",
    "    ax.bar(x + width/2, ls_means, width, yerr=ls_stds,\n",
    "           label='Ls (Spatial Lag)', color=PERFORMANCE_COLORS['tertiary'],\n",
    "           alpha=0.8, capsize=5, error_kw={'linewidth': 2})\n",
    "\n",
    "    ax.set_xlabel('Prediction Horizon (months)')\n",
    "    ax.set_ylabel('Coefficient Value')\n",
    "    ax.set_title('(A) Feature Coefficients with Standard Deviation',\n",
    "                 fontweight='bold', loc='left')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{h}' for h in avg_coefs['horizon'].values])\n",
    "    ax.legend(frameon=True)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "\n",
    "    # Add value labels\n",
    "    for i in range(len(avg_coefs)):\n",
    "        ax.text(i - width/2, lt_means[i] + lt_stds[i] + 0.05,\n",
    "                f'{lt_means[i]:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "        ax.text(i + width/2, ls_means[i] + ls_stds[i] + 0.05,\n",
    "                f'{ls_means[i]:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # 2. Relative importance (ratio)\n",
    "    ax = axes[1]\n",
    "\n",
    "    lt_ls_ratio = lt_means / np.where(ls_means != 0, ls_means, 1)\n",
    "\n",
    "    bars = ax.bar(x, lt_ls_ratio, color=PERFORMANCE_COLORS['quaternary'],\n",
    "                  alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "    ax.set_xlabel('Prediction Horizon (months)')\n",
    "    ax.set_ylabel('Lt / Ls Coefficient Ratio')\n",
    "    ax.set_title('(B) Temporal vs Spatial Feature Importance',\n",
    "                 fontweight='bold', loc='left')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{h}' for h in avg_coefs['horizon'].values])\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.axhline(y=1, color='red', linestyle='--', linewidth=2,\n",
    "               label='Equal importance', alpha=0.7)\n",
    "    ax.legend(frameon=True)\n",
    "\n",
    "    # Add value labels\n",
    "    for i, ratio in enumerate(lt_ls_ratio):\n",
    "        ax.text(i, ratio + 0.02, f'{ratio:.2f}x',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # Add interpretation text\n",
    "    ax.text(0.5, 0.98, 'Values > 1: Temporal lag more important\\nValues < 1: Spatial lag more important',\n",
    "            transform=ax.transAxes, ha='center', va='top',\n",
    "            fontsize=9, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '03_model_coefficients.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fdbed",
   "metadata": {},
   "source": [
    "## Figure 4: Spatial CV Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3df1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 4: Performance Stability Across Spatial Folds\n",
    "    Story: How robust is the model across different geographic regions?\n",
    "    \"\"\"\n",
    "    print(\"\\n4. Creating spatial CV stability analysis...\")\n",
    "\n",
    "    metrics = data['metrics'][data['metrics']['fold'].notna()].copy()\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    if metrics.empty:\n",
    "        print(\"   [WARNING] No fold-level metrics available, skipping...\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Stage 1 Baseline: Performance Stability Across Spatial CV Folds\\n' +\n",
    "                 'Geographic Robustness Assessment - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Metrics to analyze\n",
    "    metric_specs = [\n",
    "        ('accuracy', '(A) Accuracy by Fold', PERFORMANCE_COLORS['primary']),\n",
    "        ('recall', '(B) Recall by Fold', PERFORMANCE_COLORS['tertiary']),\n",
    "        ('precision', '(C) Precision by Fold', PERFORMANCE_COLORS['secondary']),\n",
    "        ('auc_roc', '(D) AUC-ROC by Fold', PERFORMANCE_COLORS['quaternary'])\n",
    "    ]\n",
    "\n",
    "    for idx, (metric, title, color) in enumerate(metric_specs):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "\n",
    "        # Prepare data for grouped bar chart\n",
    "        folds = sorted(metrics['fold'].unique())\n",
    "        x = np.arange(len(folds))\n",
    "        width = 0.25\n",
    "\n",
    "        for i, horizon in enumerate(horizons):\n",
    "            horizon_data = metrics[metrics['horizon'] == horizon]\n",
    "            values = []\n",
    "            for fold in folds:\n",
    "                fold_data = horizon_data[horizon_data['fold'] == fold]\n",
    "                if len(fold_data) > 0:\n",
    "                    values.append(fold_data[metric].values[0])\n",
    "                else:\n",
    "                    values.append(0)\n",
    "\n",
    "            offset = (i - len(horizons)//2) * width\n",
    "            ax.bar(x + offset, values, width, label=f'h={horizon}',\n",
    "                  alpha=0.7)\n",
    "\n",
    "        ax.set_xlabel('Spatial Fold')\n",
    "        ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "        ax.set_title(title, fontweight='bold', loc='left')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'Fold {int(f)}' for f in folds])\n",
    "        ax.legend(frameon=True, title='Horizon')\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        ax.set_ylim(0, 1.05)\n",
    "\n",
    "        # Add mean line\n",
    "        for horizon in horizons:\n",
    "            horizon_data = metrics[metrics['horizon'] == horizon]\n",
    "            if len(horizon_data) > 0:\n",
    "                mean_val = horizon_data[metric].mean()\n",
    "                ax.axhline(y=mean_val, linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '04_spatial_cv_stability.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9aeb12",
   "metadata": {},
   "source": [
    "## Figure 5: AR Failures Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ef7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 5: AR Failures Over Time\n",
    "    Story: When do AR failures occur? Any temporal patterns?\n",
    "    \"\"\"\n",
    "    print(\"\\n5. Creating temporal AR failure analysis...\")\n",
    "\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    fig, axes = plt.subplots(len(horizons), 1, figsize=(14, 4*len(horizons)), sharex=True)\n",
    "    if len(horizons) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle('Stage 1 Baseline: Temporal Distribution of AR Failures\\n' +\n",
    "                 'Missed Crisis Events by IPC Assessment Period - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    for idx, horizon in enumerate(horizons):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        # Get predictions for this horizon\n",
    "        preds = data[f'h{horizon}'].copy()\n",
    "        preds['ipc_period_start'] = pd.to_datetime(preds['ipc_period_start'])\n",
    "        preds['year_month'] = preds['ipc_period_start'].dt.to_period('M')\n",
    "\n",
    "        # Group by month - using optimal threshold columns\n",
    "        monthly = preds.groupby('year_month').agg({\n",
    "            'ipc_future_crisis': 'sum',  # Total crises\n",
    "            'ar_failure_optimal': 'sum',  # Missed crises (at optimal threshold)\n",
    "            'correct': 'sum'  # Correct predictions\n",
    "        }).reset_index()\n",
    "\n",
    "        monthly['year_month_str'] = monthly['year_month'].astype(str)\n",
    "\n",
    "        # Calculate failure rate\n",
    "        monthly['failure_rate'] = np.where(\n",
    "            monthly['y_true'] > 0,\n",
    "            monthly['ar_failure_optimal'] / monthly['y_true'] * 100,\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # Plot\n",
    "        x = np.arange(len(monthly))\n",
    "\n",
    "        ax.bar(x, monthly['y_true'], label='Total Crisis Events',\n",
    "               color=IPC_COLORS[3], alpha=0.4)\n",
    "        ax.bar(x, monthly['ar_failure_optimal'], label='AR Failures (Missed)',\n",
    "               color='#E31E24', alpha=0.9)\n",
    "\n",
    "        ax.set_ylabel('Number of Events')\n",
    "        ax.set_title(f'h={horizon} months | Avg Failure Rate: {monthly[\"failure_rate\"].mean():.1f}%',\n",
    "                    fontweight='bold', loc='left')\n",
    "        ax.legend(frameon=True, loc='upper left')\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "        # Set x-axis labels (show every 3rd month)\n",
    "        tick_positions = x[::3]\n",
    "        tick_labels = monthly['year_month_str'].values[::3]\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels, rotation=45, ha='right')\n",
    "\n",
    "        # Add twin axis for failure rate\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(x, monthly['failure_rate'], color='darkred',\n",
    "                linewidth=2, marker='o', markersize=3, label='Failure Rate (%)')\n",
    "        ax2.set_ylabel('Failure Rate (%)', color='darkred')\n",
    "        ax2.tick_params(axis='y', labelcolor='darkred')\n",
    "        ax2.set_ylim(0, 100)\n",
    "        ax2.legend(frameon=True, loc='upper right')\n",
    "\n",
    "    axes[-1].set_xlabel('IPC Assessment Period (Year-Month)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '05_ar_failures_temporal.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc600c",
   "metadata": {},
   "source": [
    "## Figure 6: Performance by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 6: Performance Heatmap by Country\n",
    "    Story: Which countries/regions are well-predicted vs problematic?\n",
    "    \"\"\"\n",
    "    print(\"\\n6. Creating country-level performance heatmap...\")\n",
    "\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(horizons), figsize=(6*len(horizons), 8))\n",
    "    if len(horizons) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle('Stage 1 Baseline: Performance Heatmap by Country\\n' +\n",
    "                 'Recall (Crisis Detection Rate) Across African Countries - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    for idx, horizon in enumerate(horizons):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        preds = data[f'h{horizon}'].copy()\n",
    "\n",
    "        # Calculate country-level metrics using optimal threshold\n",
    "        country_metrics = preds.groupby('ipc_country').agg({\n",
    "            'ipc_future_crisis': 'sum',\n",
    "            'y_pred_optimal': 'sum',\n",
    "            'correct': 'sum',\n",
    "            'ar_failure_optimal': 'sum',\n",
    "            'ipc_id': 'count'\n",
    "        }).reset_index()\n",
    "\n",
    "        country_metrics.columns = ['country', 'total_crisis', 'predicted_crisis',\n",
    "                                   'correct', 'ar_failures', 'n_obs']\n",
    "\n",
    "        # Calculate recall (crisis detection rate)\n",
    "        country_metrics['recall'] = np.where(\n",
    "            country_metrics['total_crisis'] > 0,\n",
    "            (country_metrics['total_crisis'] - country_metrics['ar_failures']) /\n",
    "            country_metrics['total_crisis'],\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # Filter countries with at least 10 crisis events\n",
    "        country_metrics = country_metrics[country_metrics['total_crisis'] >= 10]\n",
    "        country_metrics = country_metrics.sort_values('recall')\n",
    "\n",
    "        if len(country_metrics) == 0:\n",
    "            ax.text(0.5, 0.5, 'No countries with >= 10 crisis events',\n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Create horizontal bar chart\n",
    "        y = np.arange(len(country_metrics))\n",
    "        colors = plt.cm.RdYlGn(country_metrics['recall'].values)\n",
    "\n",
    "        bars = ax.barh(y, country_metrics['recall'].values, color=colors,\n",
    "                      edgecolor='black', linewidth=0.5)\n",
    "\n",
    "        ax.set_yticks(y)\n",
    "        ax.set_yticklabels(country_metrics['country'].values, fontsize=8)\n",
    "        ax.set_xlabel('Recall (Crisis Detection Rate)')\n",
    "        ax.set_title(f'h={horizon} months', fontweight='bold')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "        # Add value labels\n",
    "        for i, (recall, failures, total) in enumerate(zip(\n",
    "            country_metrics['recall'].values,\n",
    "            country_metrics['ar_failures'].values,\n",
    "            country_metrics['total_crisis'].values\n",
    "        )):\n",
    "            ax.text(recall + 0.02, i, f'{recall:.2f} ({int(failures)}/{int(total)})',\n",
    "                   va='center', fontsize=7)\n",
    "\n",
    "        # Add vertical line at 0.8 (good performance threshold)\n",
    "        ax.axvline(x=0.8, color='green', linestyle='--', linewidth=1.5,\n",
    "                  alpha=0.5, label='80% threshold')\n",
    "        ax.legend(frameon=True, loc='lower right', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '06_performance_by_country.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c89c37",
   "metadata": {},
   "source": [
    "## Figure 7: Feature Space Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e079ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 7: Feature Space Distribution (Lt vs Ls)\n",
    "    Story: How do crisis and non-crisis cases separate in feature space?\n",
    "    \"\"\"\n",
    "    print(\"\\n7. Creating feature space analysis...\")\n",
    "\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(horizons), figsize=(6*len(horizons), 5))\n",
    "    if len(horizons) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle('Stage 1 Baseline: Feature Space Distribution\\n' +\n",
    "                 'Lt (Temporal) vs Ls (Spatial) for Crisis vs Non-Crisis - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    for idx, horizon in enumerate(horizons):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        preds = data[f'h{horizon}'].copy()\n",
    "\n",
    "        # Check if Lt and Ls columns exist\n",
    "        if 'Lt' not in preds.columns or 'Ls' not in preds.columns:\n",
    "            ax.text(0.5, 0.5, 'Lt/Ls features not available',\n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Sample for visualization (too many points)\n",
    "        sample_size = min(2000, len(preds))\n",
    "        preds_sample = preds.sample(n=sample_size, random_state=42)\n",
    "\n",
    "        # Separate by true label\n",
    "        crisis = preds_sample[preds_sample['y_true'] == 1]\n",
    "        no_crisis = preds_sample[preds_sample['y_true'] == 0]\n",
    "\n",
    "        # Scatter plot\n",
    "        ax.scatter(no_crisis['Lt'], no_crisis['Ls'],\n",
    "                  c='#6ABD45', alpha=0.4, s=20, label='No Crisis (y=0)',\n",
    "                  edgecolors='none')\n",
    "        ax.scatter(crisis['Lt'], crisis['Ls'],\n",
    "                  c='#F58220', alpha=0.6, s=20, label='Crisis (y=1)',\n",
    "                  edgecolors='none')\n",
    "\n",
    "        # Highlight AR failures\n",
    "        failures = crisis[crisis['ar_failure_optimal'] == 1]\n",
    "        ax.scatter(failures['Lt'], failures['Ls'],\n",
    "                  c='#E31E24', marker='x', s=50, linewidths=2,\n",
    "                  label='AR Failures', zorder=10)\n",
    "\n",
    "        ax.set_xlabel('Lt (Temporal Lag - Previous IPC)')\n",
    "        ax.set_ylabel('Ls (Spatial Lag - Neighbor IPC)')\n",
    "        ax.set_title(f'h={horizon} months | AR Failures: {len(failures)}',\n",
    "                    fontweight='bold')\n",
    "        ax.legend(frameon=True, loc='upper left')\n",
    "        ax.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "        # Add IPC phase lines\n",
    "        for phase in [1, 2, 3, 4, 5]:\n",
    "            ax.axhline(y=phase, color='gray', linestyle=':', alpha=0.3, linewidth=0.5)\n",
    "            ax.axvline(x=phase, color='gray', linestyle=':', alpha=0.3, linewidth=0.5)\n",
    "\n",
    "        # Annotate IPC phases\n",
    "        ax.text(0.98, 0.02, 'IPC Phase:\\n1=Minimal\\n2=Stressed\\n3=Crisis\\n4=Emergency\\n5=Famine',\n",
    "               transform=ax.transAxes, ha='right', va='bottom',\n",
    "               fontsize=7, bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '07_feature_space_distribution.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac6957",
   "metadata": {},
   "source": [
    "## Figure 8: Prediction Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 8: Prediction Calibration\n",
    "    Story: Are predicted probabilities well-calibrated?\n",
    "    \"\"\"\n",
    "    print(\"\\n8. Creating calibration analysis...\")\n",
    "\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(horizons), figsize=(5*len(horizons), 5))\n",
    "    if len(horizons) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle('Stage 1 Baseline: Prediction Probability Calibration\\n' +\n",
    "                 'Predicted Probability vs Observed Crisis Rate - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    for idx, horizon in enumerate(horizons):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        preds = data[f'h{horizon}'].copy()\n",
    "\n",
    "        # Create probability bins\n",
    "        preds['prob_bin'] = pd.cut(preds['y_pred_proba'],\n",
    "                                   bins=10, labels=False)\n",
    "\n",
    "        # Calculate observed rate per bin\n",
    "        calibration = preds.groupby('prob_bin').agg({\n",
    "            'ipc_future_crisis': 'mean',\n",
    "            'pred_prob': 'mean',\n",
    "            'ipc_id': 'count'\n",
    "        }).reset_index()\n",
    "\n",
    "        calibration.columns = ['bin', 'observed_rate', 'mean_pred_prob', 'count']\n",
    "        calibration = calibration.dropna()\n",
    "\n",
    "        if len(calibration) == 0:\n",
    "            ax.text(0.5, 0.5, 'Insufficient calibration data',\n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            continue\n",
    "\n",
    "        # Plot calibration curve\n",
    "        ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Perfect Calibration')\n",
    "        ax.plot(calibration['mean_pred_prob'], calibration['observed_rate'],\n",
    "               'o-', linewidth=2, markersize=8, color=PERFORMANCE_COLORS['primary'],\n",
    "               label='Model Calibration')\n",
    "\n",
    "        # Add sample size as bubble size\n",
    "        max_count = calibration['count'].max()\n",
    "        if max_count > 0:\n",
    "            sizes = calibration['count'] / max_count * 500\n",
    "            ax.scatter(calibration['mean_pred_prob'], calibration['observed_rate'],\n",
    "                      s=sizes, alpha=0.3, color=PERFORMANCE_COLORS['primary'])\n",
    "\n",
    "        ax.set_xlabel('Predicted Probability')\n",
    "        ax.set_ylabel('Observed Crisis Rate')\n",
    "        ax.set_title(f'h={horizon} months', fontweight='bold')\n",
    "        ax.legend(frameon=True)\n",
    "        ax.grid(alpha=0.3, linestyle='--')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        # Add calibration error\n",
    "        calibration_error = np.abs(\n",
    "            calibration['observed_rate'] - calibration['mean_pred_prob']\n",
    "        ).mean()\n",
    "        ax.text(0.05, 0.95, f'Mean Calibration Error:\\n{calibration_error:.3f}',\n",
    "               transform=ax.transAxes, ha='left', va='top',\n",
    "               fontsize=9, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '08_prediction_calibration.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316d8b3",
   "metadata": {},
   "source": [
    "## Figure 9: ROC and PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbda990",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 9: ROC Curves for All Horizons\n",
    "    Story: Visual representation of model discrimination ability\n",
    "    \"\"\"\n",
    "    print(\"\\n9. Creating ROC curves...\")\n",
    "\n",
    "    horizons = data['horizons']\n",
    "    metrics = data['metrics'][data['metrics']['fold'].isna()].copy()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle('Stage 1 Baseline: ROC and Precision-Recall Curves\\n' +\n",
    "                 'Model Discrimination Performance - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Color palette for horizons\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "    # (A) ROC Curves\n",
    "    ax = axes[0]\n",
    "\n",
    "    for idx, horizon in enumerate(horizons):\n",
    "        preds = data[f'h{horizon}'].copy()\n",
    "        y_true = preds['y_true'].values\n",
    "        y_scores = preds['y_pred_proba'].values\n",
    "\n",
    "        # Compute ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Plot ROC curve\n",
    "        ax.plot(fpr, tpr, color=colors[idx % len(colors)], linewidth=2.5,\n",
    "                label=f'h={horizon} months (AUC = {roc_auc:.3f})')\n",
    "\n",
    "        # Find and mark optimal threshold (Youden's J)\n",
    "        j_scores = tpr - fpr\n",
    "        optimal_idx = np.argmax(j_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        ax.scatter([fpr[optimal_idx]], [tpr[optimal_idx]],\n",
    "                  marker='o', s=100, color=colors[idx % len(colors)],\n",
    "                  edgecolors='black', linewidth=2, zorder=5)\n",
    "\n",
    "    # Plot diagonal (random classifier)\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Random Classifier')\n",
    "\n",
    "    ax.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=11)\n",
    "    ax.set_ylabel('True Positive Rate (Sensitivity/Recall)', fontsize=11)\n",
    "    ax.set_title('(A) ROC Curves by Prediction Horizon', fontweight='bold', loc='left')\n",
    "    ax.legend(loc='lower right', frameon=True, fontsize=10)\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "    ax.set_xlim([-0.02, 1.02])\n",
    "    ax.set_ylim([-0.02, 1.02])\n",
    "\n",
    "    # Add annotation - for ROC curves, better is upper-left (high TPR, low FPR)\n",
    "    ax.annotate('Ideal', xy=(0, 1), xytext=(0.25, 0.75),\n",
    "               fontsize=10, ha='center',\n",
    "               arrowprops=dict(arrowstyle='->', color='green', lw=1.5),\n",
    "               bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "\n",
    "    # (B) Precision-Recall Curves\n",
    "    ax = axes[1]\n",
    "\n",
    "    for idx, horizon in enumerate(horizons):\n",
    "        preds = data[f'h{horizon}'].copy()\n",
    "        y_true = preds['y_true'].values\n",
    "        y_scores = preds['y_pred_proba'].values\n",
    "\n",
    "        # Compute Precision-Recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        # Plot PR curve\n",
    "        ax.plot(recall, precision, color=colors[idx % len(colors)], linewidth=2.5,\n",
    "                label=f'h={horizon} months (AUC-PR = {pr_auc:.3f})')\n",
    "\n",
    "        # Baseline (random classifier) - proportion of positives\n",
    "        row = metrics[metrics['horizon'] == horizon].iloc[0]\n",
    "        baseline = row['n_crisis'] / row['n_samples'] if row['n_samples'] > 0 else 0\n",
    "        ax.axhline(y=baseline, color=colors[idx % len(colors)], linestyle=':',\n",
    "                  alpha=0.5, linewidth=1)\n",
    "\n",
    "    ax.set_xlabel('Recall (Sensitivity)', fontsize=11)\n",
    "    ax.set_ylabel('Precision', fontsize=11)\n",
    "    ax.set_title('(B) Precision-Recall Curves by Prediction Horizon', fontweight='bold', loc='left')\n",
    "    ax.legend(loc='lower left', frameon=True, fontsize=10)\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "    ax.set_xlim([-0.02, 1.02])\n",
    "    ax.set_ylim([-0.02, 1.02])\n",
    "\n",
    "    # Add annotation - for PR curves, better is upper-right (high recall + high precision)\n",
    "    ax.annotate('Ideal', xy=(1, 1), xytext=(0.75, 0.75),\n",
    "               fontsize=10, ha='center',\n",
    "               arrowprops=dict(arrowstyle='->', color='green', lw=1.5),\n",
    "               bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '10_roc_pr_curves.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c4982",
   "metadata": {},
   "source": [
    "## Figure 10: ROC by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Figure 10: ROC Curves by Spatial CV Fold\n",
    "    Story: How stable is model performance across geographic regions?\n",
    "    \"\"\"\n",
    "    print(\"\\n10. Creating ROC curves by fold...\")\n",
    "\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    # Load fold-level predictions for ROC computation\n",
    "    fig, axes = plt.subplots(1, len(horizons), figsize=(6*len(horizons), 5))\n",
    "    if len(horizons) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    fig.suptitle('Stage 1 Baseline: ROC Curves by Spatial CV Fold\\n' +\n",
    "                 'Geographic Robustness of Model Discrimination - DISTRICT LEVEL',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    fold_colors = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00']\n",
    "\n",
    "    for h_idx, horizon in enumerate(horizons):\n",
    "        ax = axes[h_idx]\n",
    "\n",
    "        # Load fold-level predictions\n",
    "        folds_file = RESULTS_DIR / f'predictions_h{horizon}_district_folds.csv'\n",
    "        if folds_file.exists():\n",
    "            folds_df = pd.read_csv(folds_file)\n",
    "\n",
    "            all_aucs = []\n",
    "            for fold in sorted(folds_df['fold'].unique()):\n",
    "                fold_data = folds_df[folds_df['fold'] == fold]\n",
    "                y_true = fold_data['y_true'].values\n",
    "                y_scores = fold_data['y_pred_proba'].values\n",
    "\n",
    "                # Compute ROC curve\n",
    "                fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                all_aucs.append(roc_auc)\n",
    "\n",
    "                ax.plot(fpr, tpr, color=fold_colors[int(fold) % len(fold_colors)],\n",
    "                       linewidth=2, alpha=0.7,\n",
    "                       label=f'Fold {int(fold)} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "            # Plot mean ROC\n",
    "            ax.plot([0, 1], [0, 1], 'k--', linewidth=1.5)\n",
    "\n",
    "            # Summary stats\n",
    "            mean_auc = np.mean(all_aucs)\n",
    "            std_auc = np.std(all_aucs)\n",
    "            ax.text(0.6, 0.05, f'Mean AUC: {mean_auc:.3f} Â± {std_auc:.3f}',\n",
    "                   transform=ax.transAxes, fontsize=10,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'Fold-level predictions not found',\n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f'h={horizon} months', fontweight='bold')\n",
    "        ax.legend(loc='lower right', frameon=True, fontsize=9)\n",
    "        ax.grid(alpha=0.3, linestyle='--')\n",
    "        ax.set_xlim([-0.02, 1.02])\n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = FIGURES_DIR / '11_roc_by_fold.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8d77a",
   "metadata": {},
   "source": [
    "## Choropleth Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ce394",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Choropleth Maps - Performance by District\n",
    "    Story: Geographic visualization of model performance\n",
    "    \"\"\"\n",
    "    print(\"\\n12-14. Creating choropleth maps...\")\n",
    "\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    for horizon in horizons:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        fig.suptitle(f'Stage 1 Baseline: Geographic Performance (h={horizon} months)\\n' +\n",
    "                     'District-Level Model Performance Across Africa - DISTRICT LEVEL',\n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "        preds = data[f'h{horizon}'].copy()\n",
    "\n",
    "        # Calculate district-level metrics using optimal threshold\n",
    "        district_metrics = preds.groupby(['ipc_country', 'ipc_geographic_unit_full']).agg({\n",
    "            'avg_latitude': 'first',\n",
    "            'avg_longitude': 'first',\n",
    "            'ipc_future_crisis': 'sum',\n",
    "            'correct': 'sum',\n",
    "            'ar_failure_optimal': 'sum',\n",
    "            'ipc_id': 'count'\n",
    "        }).reset_index()\n",
    "\n",
    "        district_metrics['accuracy'] = np.where(\n",
    "            district_metrics['ipc_id'] > 0,\n",
    "            district_metrics['correct'] / district_metrics['ipc_id'],\n",
    "            0\n",
    "        )\n",
    "        district_metrics['recall'] = np.where(\n",
    "            district_metrics['y_true'] > 0,\n",
    "            1 - (district_metrics['ar_failure_optimal'] / district_metrics['y_true']),\n",
    "            1\n",
    "        )\n",
    "\n",
    "        # Filter out rows with missing coordinates\n",
    "        district_metrics = district_metrics.dropna(subset=['avg_latitude', 'avg_longitude'])\n",
    "\n",
    "        if len(district_metrics) == 0:\n",
    "            for ax in axes:\n",
    "                ax.text(0.5, 0.5, 'No geographic data available',\n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "            plt.tight_layout()\n",
    "            filename = FIGURES_DIR / f'09_choropleth_map_h{horizon}.png'\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            continue\n",
    "\n",
    "        # Map 1: Accuracy\n",
    "        ax = axes[0]\n",
    "        scatter = ax.scatter(district_metrics['avg_longitude'],\n",
    "                           district_metrics['avg_latitude'],\n",
    "                           c=district_metrics['accuracy'],\n",
    "                           s=30, cmap='RdYlGn', vmin=0, vmax=1,\n",
    "                           edgecolors='black', linewidth=0.5, alpha=0.7)\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        ax.set_title('(A) Accuracy by District', fontweight='bold', loc='left')\n",
    "        plt.colorbar(scatter, ax=ax, label='Accuracy')\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        # Map 2: AR Failures\n",
    "        ax = axes[1]\n",
    "        failure_districts = district_metrics[district_metrics['ar_failure_optimal'] > 0]\n",
    "        if len(failure_districts) > 0:\n",
    "            scatter = ax.scatter(failure_districts['avg_longitude'],\n",
    "                               failure_districts['avg_latitude'],\n",
    "                               c=failure_districts['ar_failure_optimal'],\n",
    "                               s=failure_districts['ar_failure_optimal'] * 10,\n",
    "                               cmap='Reds', edgecolors='black', linewidth=0.5, alpha=0.7)\n",
    "            plt.colorbar(scatter, ax=ax, label='Number of Failures')\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        ax.set_title('(B) AR Failures by District', fontweight='bold', loc='left')\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        # Map 3: Sample Size\n",
    "        ax = axes[2]\n",
    "        scatter = ax.scatter(district_metrics['avg_longitude'],\n",
    "                           district_metrics['avg_latitude'],\n",
    "                           c=district_metrics['ipc_id'],\n",
    "                           s=30, cmap='Blues', edgecolors='black',\n",
    "                           linewidth=0.5, alpha=0.7)\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        ax.set_title('(C) Number of Observations', fontweight='bold', loc='left')\n",
    "        plt.colorbar(scatter, ax=ax, label='Observations')\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = FIGURES_DIR / f'12_choropleth_map_h{horizon}.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"   Saved: {filename}\")\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89bd646",
   "metadata": {},
   "source": [
    "## Summary Infographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Executive Summary Infographic\n",
    "    Story: One-page visual summary for stakeholders\n",
    "    \"\"\"\n",
    "    print(\"\\n15. Creating executive summary infographic...\")\n",
    "\n",
    "    metrics = data['metrics'][data['metrics']['fold'].isna()].copy()\n",
    "    horizons = data['horizons']\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = fig.add_gridspec(4, 3, hspace=0.4, wspace=0.3)\n",
    "\n",
    "    fig.suptitle('Stage 1: Spatio-Temporal Autoregressive Baseline - DISTRICT LEVEL\\nExecutive Summary',\n",
    "                fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "    # Header stats boxes\n",
    "    for idx, horizon in enumerate(horizons[:3]):  # Max 3 horizons for display\n",
    "        row = metrics[metrics['horizon'] == horizon].iloc[0]\n",
    "\n",
    "        ax = fig.add_subplot(gs[0, idx])\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Create info box\n",
    "        box_text = f\"\"\"\n",
    "h={horizon} MONTHS AHEAD\n",
    "\n",
    "Samples: {int(row['n_samples']):,}\n",
    "Crisis Rate: {row['n_crisis']/row['n_samples']*100:.1f}%\n",
    "\n",
    "PERFORMANCE\n",
    "Accuracy: {row['accuracy']:.1%}\n",
    "Precision: {row['precision']:.1%}\n",
    "Recall: {row['recall']:.1%}\n",
    "AUC-ROC: {row['auc_roc']:.3f}\n",
    "\n",
    "AR FAILURES\n",
    "{int(row['false_negatives'])} / {int(row['n_crisis'])}\n",
    "({row['false_negatives']/row['n_crisis']*100:.1f}% missed)\n",
    "        \"\"\"\n",
    "\n",
    "        color = PERFORMANCE_COLORS['primary'] if idx == 0 else \\\n",
    "                PERFORMANCE_COLORS['tertiary'] if idx == 1 else \\\n",
    "                PERFORMANCE_COLORS['quaternary']\n",
    "\n",
    "        ax.text(0.5, 0.5, box_text.strip(), transform=ax.transAxes,\n",
    "               ha='center', va='center', fontsize=11,\n",
    "               bbox=dict(boxstyle='round,pad=1', facecolor=color, alpha=0.2,\n",
    "                        edgecolor='black', linewidth=2))\n",
    "\n",
    "    # Key Findings text\n",
    "    ax = fig.add_subplot(gs[3, :])\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Calculate summary stats dynamically\n",
    "    avg_accuracy = metrics['accuracy'].mean()\n",
    "    avg_recall = metrics['recall'].mean()\n",
    "    avg_auc = metrics['auc_roc'].mean()\n",
    "    total_failures = metrics['false_negatives'].sum()\n",
    "    total_crisis = metrics['n_crisis'].sum()\n",
    "    failure_pct = (total_failures / total_crisis * 100) if total_crisis > 0 else 0\n",
    "\n",
    "    findings_text = f\"\"\"\n",
    "KEY FINDINGS & IMPLICATIONS FOR STAGE 2 - DISTRICT LEVEL\n",
    "\n",
    "1. STRONG BASELINE PERFORMANCE: AR model achieves {avg_accuracy:.1%} average accuracy across all horizons, demonstrating strong structural persistence in IPC dynamics.\n",
    "\n",
    "2. TEMPORAL > SPATIAL: Lt (temporal lag) coefficients consistently exceed Ls (spatial lag) coefficients, indicating past IPC values\n",
    "   are stronger predictors than neighbor values at the district level.\n",
    "\n",
    "3. AR FAILURES IDENTIFY STAGE 2 TARGET: {failure_pct:.1f}% of crises are missed ({int(total_failures):,} events), representing sudden deteriorations where structural persistence\n",
    "   fails. These are precisely the cases where dynamic news signals should provide early-warning value.\n",
    "\n",
    "4. HORIZON DEGRADATION: Performance decreases at longer horizons, suggesting increased uncertainty further into\n",
    "   the future where dynamic signals may be especially valuable.\n",
    "\n",
    "5. GEOGRAPHIC HETEROGENEITY: Substantial variation in recall across countries, indicating regional differences in predictability that justify\n",
    "   mixed-effects modeling in Stage 2.\n",
    "\n",
    "NEXT STEPS: Proceed to Stage 2 - Use dynamic news features (GDELT) to explain AR failures and improve early-warning for sudden crisis onset.\n",
    "    \"\"\"\n",
    "\n",
    "    ax.text(0.5, 0.5, findings_text.strip(), transform=ax.transAxes,\n",
    "           ha='center', va='center', fontsize=10, family='monospace',\n",
    "           bbox=dict(boxstyle='round,pad=1', facecolor='lightyellow',\n",
    "                    alpha=0.8, edgecolor='black', linewidth=2))\n",
    "\n",
    "    filename = FIGURES_DIR / '15_executive_summary.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c89506",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"=\" * 80)\n",
    "    print(\"Stage 1: Publication-Grade Visualizations - DISTRICT LEVEL\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Start time: {datetime.now()}\\n\")\n",
    "\n",
    "    # Load data\n",
    "    data = load_data()\n",
    "\n",
    "    # Generate all visualizations\n",
    "    plot_1_performance_overview(data)\n",
    "    plot_2_confusion_matrices(data)\n",
    "    plot_3_model_coefficients(data)\n",
    "    plot_4_spatial_cv_stability(data)\n",
    "    plot_5_ar_failures_temporal(data)\n",
    "    plot_6_performance_by_country(data)\n",
    "    plot_7_feature_space_distribution(data)\n",
    "    plot_8_prediction_calibration(data)\n",
    "    plot_9_roc_curves(data)  # NEW: ROC and PR curves\n",
    "    plot_10_roc_by_fold(data)  # NEW: ROC by spatial fold\n",
    "    create_choropleth_maps(data)\n",
    "    create_summary_infographic(data)\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Visualization Complete - DISTRICT LEVEL\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nAll figures saved to: {FIGURES_DIR}\")\n",
    "    print(f\"Total figures created: 15+ (including ROC and PR curves)\")\n",
    "    print(f\"\\nEnd time: {datetime.now()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
