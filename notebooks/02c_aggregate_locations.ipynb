{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-header",
   "metadata": {},
   "source": [
    "# Location Aggregation - District Level\n",
    "\n",
    "**Script**: `scripts/02_data_processing/03_aggregate_locations.py`\n",
    "\n",
    "**Author**: Victor Collins Oppon, MSc Data Science, Middlesex University 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Aggregates GDELT location mentions to IPC district-period observations using:\n",
    "- **4-month temporal windows** (3 months before + assessment month)\n",
    "- **Geographic matching hierarchy**: GADM3 (district) → GADM2 (zone) → GADM1 (state) → Country-level\n",
    "- **Fuzzy matching**: 80% threshold for district name matching\n",
    "- **Word-based lookup**: For LHZ countries (Zimbabwe, Burundi, Kenya)\n",
    "\n",
    "**CRITICAL ALIGNMENT**: Uses identical temporal windows and matching strategy as `02_aggregate_articles.py`\n",
    "\n",
    "**Runtime**: ~30 minutes (5.2M location mentions processed)\n",
    "\n",
    "**Input**: \n",
    "- `data/external/gdelt/african_gkg_locations_aligned.parquet` (613MB)\n",
    "- `data/district_level/ipc_reference.parquet` (from 02a)\n",
    "\n",
    "**Output**: `data/district_level/locations_aggregated.parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "import unicodedata\n",
    "import gc\n",
    "from config import BASE_DIR\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(str(BASE_DIR.parent.parent.parent))\n",
    "LOCATIONS_FILE = BASE_DIR / 'aligned_data' / 'african_gkg_locations_aligned.parquet'\n",
    "\n",
    "# IPC reference from previous step\n",
    "DISTRICT_DATA_DIR = BASE_DIR / 'data' / 'district_level'\n",
    "IPC_REF_FILE = DISTRICT_DATA_DIR / 'ipc_reference.parquet'\n",
    "\n",
    "# Output\n",
    "OUTPUT_PARQUET = DISTRICT_DATA_DIR / 'locations_aggregated.parquet'\n",
    "OUTPUT_CSV = DISTRICT_DATA_DIR / 'locations_aggregated.csv'\n",
    "\n",
    "print(f\"Locations file: {LOCATIONS_FILE}\")\n",
    "print(f\"IPC reference: {IPC_REF_FILE}\")\n",
    "print(f\"Output: {OUTPUT_PARQUET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constants-header",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constants",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal aggregation window (ALIGNED WITH 02_aggregate_articles.py)\n",
    "AGGREGATION_MONTHS = 4  # 3 months before + assessment month\n",
    "\n",
    "# Fuzzy matching threshold\n",
    "FUZZY_THRESHOLD = 80  # 80% similarity\n",
    "\n",
    "# Chunk size for processing\n",
    "CHUNK_SIZE = 1000000\n",
    "\n",
    "# Countries with ONLY national-level IPC data (ALIGNED WITH 02_aggregate_articles.py)\n",
    "COUNTRY_LEVEL_ONLY = {'AO', 'CG', 'CT', 'LT', 'MR', 'RW', 'TO'}\n",
    "\n",
    "print(f\"Aggregation window: {AGGREGATION_MONTHS} months\")\n",
    "print(f\"Fuzzy threshold: {FUZZY_THRESHOLD}%\")\n",
    "print(f\"Chunk size: {CHUNK_SIZE:,}\")\n",
    "print(f\"Country-level only: {COUNTRY_LEVEL_ONLY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functions-header",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Functions for text normalization, fuzzy matching, and lookup building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text for matching with accent removal - ALIGNED WITH 02_aggregate_articles.py\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = str(text).lower().strip()\n",
    "    # Remove accents (e.g., Kasaï -> kasai, Équateur -> equateur)\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    text = ''.join(c if c.isalnum() or c.isspace() else ' ' for c in text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "print(\"Test normalization:\")\n",
    "print(f\"  'Kasaï Central' → '{normalize_text('Kasaï Central')}'\")\n",
    "print(f\"  'Nord-Kivu' → '{normalize_text('Nord-Kivu')}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-match-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fuzzy_match(loc_name_norm, ipc_candidates, country_code):\n",
    "    \"\"\"\n",
    "    Find best fuzzy match for location name among IPC district candidates.\n",
    "    Returns: (ipc_info_list, match_score) or (None, 0)\n",
    "    \"\"\"\n",
    "    if not loc_name_norm or not ipc_candidates:\n",
    "        return None, 0\n",
    "\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for (fips, district_norm), ipc_list in ipc_candidates.items():\n",
    "        if fips != country_code:\n",
    "            continue\n",
    "\n",
    "        score = fuzz.ratio(loc_name_norm, district_norm)\n",
    "\n",
    "        if score >= FUZZY_THRESHOLD and score > best_score:\n",
    "            best_score = score\n",
    "            best_match = ipc_list\n",
    "\n",
    "    return best_match, best_score\n",
    "\n",
    "print(\"find_fuzzy_match defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "word-lookup-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_lookup(ipc_ref):\n",
    "    \"\"\"\n",
    "    Build word-based lookup from full_name_normalized at startup.\n",
    "    ALIGNED WITH 02_aggregate_articles.py\n",
    "\n",
    "    This enables matching for livelihood zone countries (Zimbabwe, Burundi, Kenya, etc.)\n",
    "    where IPC uses names like \"agrofisheries binga matabeleland north zimbabwe\"\n",
    "    that contain embedded GADM admin names.\n",
    "    \"\"\"\n",
    "    print(\"   Building word-based lookup from full_name_normalized...\", flush=True)\n",
    "    word_lookup = defaultdict(list)\n",
    "\n",
    "    for idx, row in ipc_ref.iterrows():\n",
    "        if pd.notna(row['fips_code']) and pd.notna(row.get('full_name_normalized')):\n",
    "            country = row['fips_code']\n",
    "            full_name_norm = normalize_text(row['full_name_normalized'])\n",
    "            words = full_name_norm.split()\n",
    "\n",
    "            # Calculate 4-month aggregation window (3 months before + assessment month)\n",
    "            # ALIGNED WITH 02_aggregate_articles.py\n",
    "            ipc_period_end = pd.to_datetime(row['projection_end'])\n",
    "            ipc_period_start = pd.to_datetime(row['projection_start'])\n",
    "            agg_window_start = ipc_period_start - relativedelta(months=AGGREGATION_MONTHS - 1)\n",
    "            agg_window_end = ipc_period_end  # End at assessment month end\n",
    "\n",
    "            # Build IPC info dict (same structure as main lookup)\n",
    "            ipc_info = {\n",
    "                'ipc_id': row['ipc_id'],\n",
    "                'ipc_country': row['country'],\n",
    "                'ipc_country_code': row['country_code'],\n",
    "                'ipc_fips_code': row['fips_code'],\n",
    "                'ipc_district': row['district'],\n",
    "                'ipc_region': row['region'],\n",
    "                'ipc_geographic_unit': row['geographic_unit_name'],\n",
    "                'ipc_geographic_unit_full': row['geographic_unit_full_name'],\n",
    "                'ipc_period_start': ipc_period_start,\n",
    "                'ipc_period_end': ipc_period_end,\n",
    "                'agg_window_start': agg_window_start,  # 4-month window start\n",
    "                'agg_window_end': agg_window_end,      # 4-month window end\n",
    "                'ipc_period_length_days': row['period_length_days'],\n",
    "                'ipc_value': row['ipc_value'],\n",
    "                'ipc_description': row['ipc_description'],\n",
    "                'ipc_binary_crisis': row['ipc_binary_crisis'],\n",
    "                'ipc_is_allowing_assistance': row['is_allowing_for_assistance'],\n",
    "                'ipc_fewsnet_region': row['fewsnet_region'],\n",
    "                'ipc_geographic_group': row['geographic_group'],\n",
    "                'ipc_scenario': row['scenario'],\n",
    "                'ipc_classification_scale': row['classification_scale'],\n",
    "                'ipc_reporting_date': row['reporting_date'],\n",
    "            }\n",
    "\n",
    "            for word in words:\n",
    "                if len(word) > 2:  # Skip short words\n",
    "                    key = (country, word)\n",
    "                    word_lookup[key].append(ipc_info)\n",
    "\n",
    "    print(f\"   Word-based lookup: {len(word_lookup):,} keys\", flush=True)\n",
    "    return word_lookup\n",
    "\n",
    "print(\"build_word_lookup defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processing-header",
   "metadata": {},
   "source": [
    "## Main Processing\n",
    "\n",
    "Load IPC reference, build lookups, process locations, and aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-ipc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"GDELT Locations - DISTRICT LEVEL Alignment\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Start time: {datetime.now()}\")\n",
    "print(f\"Fuzzy matching threshold: {FUZZY_THRESHOLD}\")\n",
    "\n",
    "# Load IPC reference\n",
    "print(\"\\n1. Loading IPC district reference data...\")\n",
    "ipc_ref = pd.read_parquet(IPC_REF_FILE)\n",
    "print(f\"   Loaded {len(ipc_ref):,} IPC periods\")\n",
    "print(f\"   Unique districts: {ipc_ref['district'].nunique():,}\")\n",
    "\n",
    "# Show sample\n",
    "ipc_ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-ipc-lookup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lookup dictionary - KEY CHANGE: Index by district_normalized\n",
    "print(\"\\n2. Building IPC district lookup dictionary...\")\n",
    "ipc_lookup = defaultdict(list)\n",
    "\n",
    "for idx, row in ipc_ref.iterrows():\n",
    "    if pd.notna(row['fips_code']) and pd.notna(row['district_normalized']):\n",
    "        # Calculate 4-month aggregation window (3 months before + assessment month)\n",
    "        # ALIGNED WITH 02_aggregate_articles.py\n",
    "        ipc_period_end = pd.to_datetime(row['projection_end'])\n",
    "        ipc_period_start = pd.to_datetime(row['projection_start'])\n",
    "        agg_window_start = ipc_period_start - relativedelta(months=AGGREGATION_MONTHS - 1)\n",
    "        agg_window_end = ipc_period_end  # End at assessment month end\n",
    "\n",
    "        key = (row['fips_code'], row['district_normalized'])\n",
    "        ipc_lookup[key].append({\n",
    "            'ipc_id': row['ipc_id'],\n",
    "            'ipc_country': row['country'],\n",
    "            'ipc_country_code': row['country_code'],\n",
    "            'ipc_fips_code': row['fips_code'],\n",
    "            'ipc_district': row['district'],\n",
    "            'ipc_region': row['region'],\n",
    "            'ipc_geographic_unit': row['geographic_unit_name'],\n",
    "            'ipc_geographic_unit_full': row['geographic_unit_full_name'],\n",
    "            'ipc_period_start': ipc_period_start,\n",
    "            'ipc_period_end': ipc_period_end,\n",
    "            'agg_window_start': agg_window_start,  # 4-month window start\n",
    "            'agg_window_end': agg_window_end,      # 4-month window end\n",
    "            'ipc_period_length_days': row['period_length_days'],\n",
    "            'ipc_value': row['ipc_value'],\n",
    "            'ipc_description': row['ipc_description'],\n",
    "            'ipc_binary_crisis': row['ipc_binary_crisis'],\n",
    "            'ipc_is_allowing_assistance': row['is_allowing_for_assistance'],\n",
    "            'ipc_fewsnet_region': row['fewsnet_region'],\n",
    "            'ipc_geographic_group': row['geographic_group'],\n",
    "            'ipc_scenario': row['scenario'],\n",
    "            'ipc_classification_scale': row['classification_scale'],\n",
    "            'ipc_reporting_date': row['reporting_date'],\n",
    "        })\n",
    "\n",
    "print(f\"   Created lookup with {len(ipc_lookup):,} unique (country, district) combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-word-lookup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build word-based lookup from full_name_normalized (ALIGNED WITH 02_aggregate_articles.py)\n",
    "word_lookup = build_word_lookup(ipc_ref)\n",
    "\n",
    "# Combine word_lookup with ipc_lookup (ipc_lookup takes precedence)\n",
    "combined_lookup = defaultdict(list)\n",
    "for k, v in word_lookup.items():\n",
    "    combined_lookup[k].extend(v)\n",
    "for k, v in ipc_lookup.items():\n",
    "    combined_lookup[k].extend(v)\n",
    "print(f\"   Combined lookup: {len(combined_lookup):,} keys\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matching-header",
   "metadata": {},
   "source": [
    "## Location Matching and Aggregation\n",
    "\n",
    "Process locations in chunks with hierarchical matching: GADM3 → GADM2 → GADM1 → Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-locations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process locations in chunks\n",
    "# KEY CHANGE: Match via GADM3 → GADM2 → GADM1 (ALIGNED WITH 02_aggregate_articles.py)\n",
    "print(\"\\n3. Processing locations with DISTRICT-level matching...\", flush=True)\n",
    "print(\"   Priority: GADM3 -> GADM2 -> GADM1 (aligned with articles script)\", flush=True)\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "parquet_file = pq.ParquetFile(LOCATIONS_FILE)\n",
    "\n",
    "all_aggregations = []\n",
    "total_processed = 0\n",
    "total_matched = 0\n",
    "match_stats = {\n",
    "    'GADM3_exact': 0, 'GADM3_fuzzy': 0,\n",
    "    'GADM2_exact': 0, 'GADM2_fuzzy': 0,\n",
    "    'GADM1_exact': 0, 'GADM1_fuzzy': 0,  # Added GADM1 - ALIGNED WITH 02_aggregate_articles.py\n",
    "    'Country_level': 0,\n",
    "    'no_match': 0\n",
    "}\n",
    "\n",
    "for batch_num, batch in enumerate(parquet_file.iter_batches(batch_size=CHUNK_SIZE)):\n",
    "    chunk_start = datetime.now()\n",
    "    locations_chunk = batch.to_pandas()\n",
    "\n",
    "    print(f\"\\n   Batch {batch_num + 1}: Processing {len(locations_chunk):,} locations...\", flush=True)\n",
    "\n",
    "    locations_chunk['date_extracted'] = pd.to_datetime(locations_chunk['date_extracted'])\n",
    "\n",
    "    # Normalize geographic fields (including GADM1 - ALIGNED WITH 02_aggregate_articles.py)\n",
    "    locations_chunk['gadm1_norm'] = locations_chunk['gadm1_name'].apply(normalize_text)\n",
    "    locations_chunk['gadm2_norm'] = locations_chunk['gadm2_name'].apply(normalize_text)\n",
    "    locations_chunk['gadm3_norm'] = locations_chunk['gadm3_name'].apply(normalize_text)\n",
    "\n",
    "    matched_records = []\n",
    "    matched_ipc_ids = set()\n",
    "\n",
    "    # Group by country for efficiency\n",
    "    for country_code, country_locs in locations_chunk.groupby('african_country_code'):\n",
    "\n",
    "        # ================================================================\n",
    "        # PRIORITY 1: GADM3 Matching (Exact → Fuzzy)\n",
    "        # GADM3 corresponds to district/woreda level\n",
    "        # ================================================================\n",
    "        for gadm3_norm, gadm3_locs in country_locs.groupby('gadm3_norm'):\n",
    "            if not gadm3_norm:\n",
    "                continue\n",
    "\n",
    "            key = (country_code, gadm3_norm)\n",
    "            matched_ipc_list = None\n",
    "            match_type = None\n",
    "            match_score = 0\n",
    "\n",
    "            if key in combined_lookup:\n",
    "                matched_ipc_list = combined_lookup[key]\n",
    "                match_type = 'GADM3_exact'\n",
    "                match_score = 100\n",
    "            else:\n",
    "                matched_ipc_list, match_score = find_fuzzy_match(gadm3_norm, combined_lookup, country_code)\n",
    "                if matched_ipc_list:\n",
    "                    match_type = 'GADM3_fuzzy'\n",
    "\n",
    "            if matched_ipc_list:\n",
    "                for ipc_info in matched_ipc_list:\n",
    "                    # Use ipc_geographic_unit_full as unique key (not just ipc_id)\n",
    "                    ipc_key = (ipc_info['ipc_id'], ipc_info['ipc_geographic_unit_full'])\n",
    "                    if ipc_key in matched_ipc_ids:\n",
    "                        continue\n",
    "\n",
    "                    # Use 4-month aggregation window (ALIGNED WITH 02_aggregate_articles.py)\n",
    "                    date_mask = (\n",
    "                        (gadm3_locs['date_extracted'] >= ipc_info['agg_window_start']) &\n",
    "                        (gadm3_locs['date_extracted'] <= ipc_info['agg_window_end'])\n",
    "                    )\n",
    "                    period_locs = gadm3_locs[date_mask]\n",
    "\n",
    "                    if len(period_locs) > 0:\n",
    "                        agg_data = {\n",
    "                            'location_mention_count': len(period_locs),\n",
    "                            'unique_location_names': period_locs['location_fullname'].nunique(),\n",
    "                            'unique_cities': period_locs['city_name'].nunique() if 'city_name' in period_locs.columns else 0,\n",
    "                            'unique_days': period_locs['date_extracted'].nunique(),\n",
    "                            'avg_latitude': period_locs['latitude'].mean(),\n",
    "                            'avg_longitude': period_locs['longitude'].mean(),\n",
    "                            'latitude_std': period_locs['latitude'].std(),\n",
    "                            'longitude_std': period_locs['longitude'].std(),\n",
    "                            'primary_gadm2': period_locs['gadm2_name'].mode()[0] if not period_locs['gadm2_name'].mode().empty else None,\n",
    "                            'primary_gadm3': period_locs['gadm3_name'].mode()[0] if not period_locs['gadm3_name'].mode().empty else None,\n",
    "                            'match_level': match_type,\n",
    "                            'match_score': match_score,\n",
    "                            **ipc_info\n",
    "                        }\n",
    "                        matched_records.append(agg_data)\n",
    "                        matched_ipc_ids.add(ipc_key)\n",
    "                        match_stats[match_type] += 1\n",
    "\n",
    "        # ================================================================\n",
    "        # PRIORITY 2: GADM2 Matching (Exact → Fuzzy)\n",
    "        # GADM2 is zone/province level - use as fallback\n",
    "        # ================================================================\n",
    "        for gadm2_norm, gadm2_locs in country_locs.groupby('gadm2_norm'):\n",
    "            if not gadm2_norm:\n",
    "                continue\n",
    "\n",
    "            key = (country_code, gadm2_norm)\n",
    "            matched_ipc_list = None\n",
    "            match_type = None\n",
    "            match_score = 0\n",
    "\n",
    "            if key in combined_lookup:\n",
    "                matched_ipc_list = combined_lookup[key]\n",
    "                match_type = 'GADM2_exact'\n",
    "                match_score = 100\n",
    "            else:\n",
    "                matched_ipc_list, match_score = find_fuzzy_match(gadm2_norm, combined_lookup, country_code)\n",
    "                if matched_ipc_list:\n",
    "                    match_type = 'GADM2_fuzzy'\n",
    "\n",
    "            if matched_ipc_list:\n",
    "                for ipc_info in matched_ipc_list:\n",
    "                    ipc_key = (ipc_info['ipc_id'], ipc_info['ipc_geographic_unit_full'])\n",
    "                    if ipc_key in matched_ipc_ids:\n",
    "                        continue\n",
    "\n",
    "                    # Use 4-month aggregation window (ALIGNED WITH 02_aggregate_articles.py)\n",
    "                    date_mask = (\n",
    "                        (gadm2_locs['date_extracted'] >= ipc_info['agg_window_start']) &\n",
    "                        (gadm2_locs['date_extracted'] <= ipc_info['agg_window_end'])\n",
    "                    )\n",
    "                    period_locs = gadm2_locs[date_mask]\n",
    "\n",
    "                    if len(period_locs) > 0:\n",
    "                        agg_data = {\n",
    "                            'location_mention_count': len(period_locs),\n",
    "                            'unique_location_names': period_locs['location_fullname'].nunique(),\n",
    "                            'unique_cities': period_locs['city_name'].nunique() if 'city_name' in period_locs.columns else 0,\n",
    "                            'unique_days': period_locs['date_extracted'].nunique(),\n",
    "                            'avg_latitude': period_locs['latitude'].mean(),\n",
    "                            'avg_longitude': period_locs['longitude'].mean(),\n",
    "                            'latitude_std': period_locs['latitude'].std(),\n",
    "                            'longitude_std': period_locs['longitude'].std(),\n",
    "                            'primary_gadm2': period_locs['gadm2_name'].mode()[0] if not period_locs['gadm2_name'].mode().empty else None,\n",
    "                            'primary_gadm3': period_locs['gadm3_name'].mode()[0] if not period_locs['gadm3_name'].mode().empty else None,\n",
    "                            'match_level': match_type,\n",
    "                            'match_score': match_score,\n",
    "                            **ipc_info\n",
    "                        }\n",
    "                        matched_records.append(agg_data)\n",
    "                        matched_ipc_ids.add(ipc_key)\n",
    "                        match_stats[match_type] += 1\n",
    "\n",
    "        # ================================================================\n",
    "        # PRIORITY 3: GADM1 Matching (State/Region level)\n",
    "        # Important for countries like Nigeria where IPC uses state-level\n",
    "        # ALIGNED WITH 02_aggregate_articles.py\n",
    "        # ================================================================\n",
    "        for gadm1_norm, gadm1_locs in country_locs.groupby('gadm1_norm'):\n",
    "            if not gadm1_norm:\n",
    "                continue\n",
    "\n",
    "            key = (country_code, gadm1_norm)\n",
    "            matched_ipc_list = None\n",
    "            match_type = None\n",
    "            match_score = 0\n",
    "\n",
    "            if key in combined_lookup:\n",
    "                matched_ipc_list = combined_lookup[key]\n",
    "                match_type = 'GADM1_exact'\n",
    "                match_score = 100\n",
    "            else:\n",
    "                matched_ipc_list, match_score = find_fuzzy_match(gadm1_norm, combined_lookup, country_code)\n",
    "                if matched_ipc_list:\n",
    "                    match_type = 'GADM1_fuzzy'\n",
    "\n",
    "            if matched_ipc_list:\n",
    "                for ipc_info in matched_ipc_list:\n",
    "                    ipc_key = (ipc_info['ipc_id'], ipc_info['ipc_geographic_unit_full'])\n",
    "                    if ipc_key in matched_ipc_ids:\n",
    "                        continue\n",
    "\n",
    "                    # Use 4-month aggregation window (ALIGNED WITH 02_aggregate_articles.py)\n",
    "                    date_mask = (\n",
    "                        (gadm1_locs['date_extracted'] >= ipc_info['agg_window_start']) &\n",
    "                        (gadm1_locs['date_extracted'] <= ipc_info['agg_window_end'])\n",
    "                    )\n",
    "                    period_locs = gadm1_locs[date_mask]\n",
    "\n",
    "                    if len(period_locs) > 0:\n",
    "                        agg_data = {\n",
    "                            'location_mention_count': len(period_locs),\n",
    "                            'unique_location_names': period_locs['location_fullname'].nunique(),\n",
    "                            'unique_cities': period_locs['city_name'].nunique() if 'city_name' in period_locs.columns else 0,\n",
    "                            'unique_days': period_locs['date_extracted'].nunique(),\n",
    "                            'avg_latitude': period_locs['latitude'].mean(),\n",
    "                            'avg_longitude': period_locs['longitude'].mean(),\n",
    "                            'latitude_std': period_locs['latitude'].std(),\n",
    "                            'longitude_std': period_locs['longitude'].std(),\n",
    "                            'primary_gadm2': period_locs['gadm2_name'].mode()[0] if not period_locs['gadm2_name'].mode().empty else None,\n",
    "                            'primary_gadm3': period_locs['gadm3_name'].mode()[0] if not period_locs['gadm3_name'].mode().empty else None,\n",
    "                            'match_level': match_type,\n",
    "                            'match_score': match_score,\n",
    "                            **ipc_info\n",
    "                        }\n",
    "                        matched_records.append(agg_data)\n",
    "                        matched_ipc_ids.add(ipc_key)\n",
    "                        match_stats[match_type] += 1\n",
    "\n",
    "        # ================================================================\n",
    "        # PRIORITY 4: Country-level matching (for countries with limited data)\n",
    "        # ================================================================\n",
    "        if country_code in COUNTRY_LEVEL_ONLY:\n",
    "            for (fips, district), ipc_list in combined_lookup.items():\n",
    "                if fips == country_code:\n",
    "                    for ipc_info in ipc_list:\n",
    "                        ipc_key = (ipc_info['ipc_id'], ipc_info['ipc_geographic_unit_full'])\n",
    "                        if ipc_key in matched_ipc_ids:\n",
    "                            continue\n",
    "\n",
    "                        # Use 4-month aggregation window (ALIGNED WITH 02_aggregate_articles.py)\n",
    "                        date_mask = (\n",
    "                            (country_locs['date_extracted'] >= ipc_info['agg_window_start']) &\n",
    "                            (country_locs['date_extracted'] <= ipc_info['agg_window_end'])\n",
    "                        )\n",
    "                        period_locs = country_locs[date_mask]\n",
    "\n",
    "                        if len(period_locs) > 0:\n",
    "                            agg_data = {\n",
    "                                'location_mention_count': len(period_locs),\n",
    "                                'unique_location_names': period_locs['location_fullname'].nunique(),\n",
    "                                'unique_cities': period_locs['city_name'].nunique() if 'city_name' in period_locs.columns else 0,\n",
    "                                'unique_days': period_locs['date_extracted'].nunique(),\n",
    "                                'avg_latitude': period_locs['latitude'].mean(),\n",
    "                                'avg_longitude': period_locs['longitude'].mean(),\n",
    "                                'latitude_std': period_locs['latitude'].std(),\n",
    "                                'longitude_std': period_locs['longitude'].std(),\n",
    "                                'primary_gadm2': period_locs['gadm2_name'].mode()[0] if not period_locs['gadm2_name'].mode().empty else None,\n",
    "                                'primary_gadm3': period_locs['gadm3_name'].mode()[0] if not period_locs['gadm3_name'].mode().empty else None,\n",
    "                                'match_level': 'Country_level',\n",
    "                                'match_score': 100,\n",
    "                                **ipc_info\n",
    "                            }\n",
    "                            matched_records.append(agg_data)\n",
    "                            matched_ipc_ids.add(ipc_key)\n",
    "                            match_stats['Country_level'] += 1\n",
    "\n",
    "    if matched_records:\n",
    "        chunk_df = pd.DataFrame(matched_records)\n",
    "        all_aggregations.append(chunk_df)\n",
    "        total_matched += len(matched_records)\n",
    "\n",
    "    total_processed += len(locations_chunk)\n",
    "    chunk_time = (datetime.now() - chunk_start).total_seconds()\n",
    "\n",
    "    print(f\"      Matched: {len(matched_records):,} IPC period-aggregations\", flush=True)\n",
    "    print(f\"      Time: {chunk_time:.1f}s\", flush=True)\n",
    "\n",
    "    del locations_chunk\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combine-header",
   "metadata": {},
   "source": [
    "## Combine and Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combine-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all aggregations\n",
    "print(f\"\\n4. Combining {len(all_aggregations)} chunks...\")\n",
    "if all_aggregations:\n",
    "    final_df = pd.concat(all_aggregations, ignore_index=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Aggregation Summary - DISTRICT LEVEL\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal locations processed: {total_processed:,}\")\n",
    "    print(f\"Total IPC period-aggregations: {len(final_df):,}\")\n",
    "    print(f\"Unique districts: {final_df['ipc_district'].nunique():,}\")\n",
    "    print(f\"Unique geographic_unit_full: {final_df['ipc_geographic_unit_full'].nunique():,}\")\n",
    "    print(f\"Date range: {final_df['ipc_period_start'].min()} to {final_df['ipc_period_end'].max()}\")\n",
    "    print(f\"Countries: {final_df['ipc_country'].nunique()}\")\n",
    "\n",
    "    print(f\"\\nGeographic Match Statistics:\")\n",
    "    for level, count in sorted(match_stats.items()):\n",
    "        if count > 0:\n",
    "            pct = (count / total_matched * 100) if total_matched > 0 else 0\n",
    "            print(f\"   {level}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nRecords by country:\")\n",
    "    print(final_df['ipc_country'].value_counts())\n",
    "else:\n",
    "    print(\"\\n   WARNING: No matched records found!\")\n",
    "    final_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## Save Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_df is not None:\n",
    "    # Save\n",
    "    print(f\"\\n5. Saving to {OUTPUT_PARQUET}...\")\n",
    "    final_df.to_parquet(OUTPUT_PARQUET, index=False)\n",
    "    print(\"   [OK] Parquet saved\")\n",
    "\n",
    "    print(f\"\\n6. Saving to {OUTPUT_CSV}...\")\n",
    "    final_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"   [OK] CSV saved\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Locations Aggregation Complete - DISTRICT LEVEL\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nKey columns for downstream scripts:\")\n",
    "    print(\"   - ipc_id: Unique IPC assessment ID\")\n",
    "    print(\"   - ipc_geographic_unit_full: THE PRIMARY GEOGRAPHIC IDENTIFIER\")\n",
    "    print(\"   - ipc_district: Extracted district name\")\n",
    "    print(\"   - location_mention_count: Number of location mentions in 4-month window\")\n",
    "    print(\"   - avg_latitude, avg_longitude: Geographic centroids\")\n",
    "else:\n",
    "    print(\"\\n   No data to save.\")\n",
    "\n",
    "print(f\"\\nEnd time: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
