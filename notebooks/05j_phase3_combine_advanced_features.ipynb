{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48338d8",
   "metadata": {},
   "source": [
    "# Phase 3: Combine Advanced Features\n",
    "\n",
    "**Script**: `scripts\\04_stage2_feature_engineering\\phase3_feature_combination\\02_combine_advanced_features.py`\n",
    "\n",
    "**Author**: Victor Collins Oppon, MSc Data Science, Middlesex University 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Combines all features including HMM and DMD into unified dataset.\n",
    "\n",
    "**ADVANCED FEATURES**:\n",
    "- Basic features (ratio + zscore + location)\n",
    "- HMM features (latent states from both ratio and zscore)\n",
    "- DMD features (temporal dynamics from both ratio and zscore)\n",
    "\n",
    "Creates: combined_advanced_features_h8.parquet\n",
    "\n",
    "**Runtime**: See script header for details\n",
    "\n",
    "**Input/Output**: See script header for file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ba7d6",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combined HMM+DMD Features - XGBoost Pipeline (REDESIGNED)\n",
    "==========================================================\n",
    "Phase 2, Step 6: Merge all feature sets (ratio + zscore + HMM + DMD) into a single dataset.\n",
    "\n",
    "REDESIGN (December 24, 2025):\n",
    "- HMM features reduced: 12 → 6 (3 ratio + 3 zscore)\n",
    "- DMD features reduced: 42 → 8 (4 ratio + 4 zscore)\n",
    "- Total feature reduction: 72 → 32 features (55% reduction)\n",
    "\n",
    "This script combines:\n",
    "1. Basic ratio features (9 macrocategories)\n",
    "2. Basic zscore features (9 macrocategories)\n",
    "3. HMM ratio features (3 outputs: crisis_prob, transition_risk, entropy)\n",
    "4. HMM zscore features (3 outputs: crisis_prob, transition_risk, entropy)\n",
    "5. DMD ratio features (4 crisis outputs)\n",
    "6. DMD zscore features (4 crisis outputs)\n",
    "7. Location encoding (country, district)\n",
    "8. Target variables and metadata\n",
    "\n",
    "Output: Comprehensive dataset with 32 features (18 base + 6 HMM + 8 DMD)\n",
    "\n",
    "Author: Victor Collins Oppon\n",
    "Date: December 2025 (Redesigned: Dec 24, 2025)\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add FINAL_PIPELINE to path (3 levels up)\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent.parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c8908",
   "metadata": {},
   "source": [
    "## Load All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BASE_DIR, STAGE2_FEATURES_DIR, RANDOM_STATE\n",
    "\n",
    "# Define Phase 2 and Phase 3 directories\n",
    "PHASE2_RESULTS = STAGE2_FEATURES_DIR / 'phase2_features'\n",
    "PHASE3_OUTPUT = STAGE2_FEATURES_DIR / 'phase3_combined'\n",
    "PHASE3_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ensure_directories():\n",
    "    \"\"\"Ensure output directories exist.\"\"\"\n",
    "    PHASE3_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Macro categories\n",
    "MACRO_CATEGORIES = ['conflict', 'displacement', 'economic', 'food_security', 'governance',\n",
    "                    'health', 'humanitarian', 'other', 'weather']\n",
    "\n",
    "def ensure_directories():\n",
    "    \"\"\"Create output directories.\"\"\"\n",
    "    PHASE3_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"XGBOOST PIPELINE - PHASE 2: COMBINED HMM+DMD FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Feature selection for XGBoost\n",
    "RATIO_FEATURES = [f'{cat}_ratio' for cat in MACRO_CATEGORIES]\n",
    "ZSCORE_FEATURES = [f'{cat}_zscore' for cat in MACRO_CATEGORIES]\n",
    "\n",
    "# REDESIGNED: HMM features reduced from 6 to 3 per type\n",
    "HMM_RATIO_FEATURES = [\n",
    "    'hmm_ratio_crisis_prob',      # P(Crisis-Prone state)\n",
    "    'hmm_ratio_transition_risk',  # P(next_state=Crisis | current_state)\n",
    "    'hmm_ratio_entropy',          # State uncertainty\n",
    "]\n",
    "\n",
    "HMM_ZSCORE_FEATURES = [\n",
    "    'hmm_zscore_crisis_prob',\n",
    "    'hmm_zscore_transition_risk',\n",
    "    'hmm_zscore_entropy',\n",
    "]\n",
    "\n",
    "# REDESIGNED: DMD features reduced from 21 to 4 per type (crisis-focused)\n",
    "DMD_RATIO_FEATURES = [\n",
    "    'dmd_ratio_crisis_growth_rate',    # Dominant crisis mode growth\n",
    "    'dmd_ratio_crisis_instability',    # Crisis-weighted sum of growing modes\n",
    "    'dmd_ratio_crisis_frequency',      # Dominant crisis oscillation period\n",
    "    'dmd_ratio_crisis_amplitude',      # Dominant crisis mode strength\n",
    "]\n",
    "\n",
    "DMD_ZSCORE_FEATURES = [\n",
    "    'dmd_zscore_crisis_growth_rate',\n",
    "    'dmd_zscore_crisis_instability',\n",
    "    'dmd_zscore_crisis_frequency',\n",
    "    'dmd_zscore_crisis_amplitude',\n",
    "]\n",
    "\n",
    "LOCATION_FEATURES = ['country_encoded', 'district_encoded']\n",
    "\n",
    "TARGET_FEATURES = ['ipc_future_crisis', 'ipc_binary_crisis_filled']\n",
    "\n",
    "AR_FEATURES = ['ar_pred_optimal_filled', 'ar_prob_filled']\n",
    "\n",
    "IPC_FEATURES = ['ipc_value_filled']\n",
    "\n",
    "METADATA_COLS = [\n",
    "    # Geographic identifiers\n",
    "    'ipc_country', 'ipc_country_code', 'ipc_fips_code',\n",
    "    'ipc_district', 'ipc_region', 'ipc_geographic_unit',\n",
    "    'ipc_geographic_unit_full', 'ipc_fewsnet_region', 'ipc_geographic_group',\n",
    "    # Spatial coordinates\n",
    "    'avg_latitude', 'avg_longitude', 'latitude_std', 'longitude_std',\n",
    "    # Temporal identifiers\n",
    "    'year_month', 'year', 'year_month_dt',\n",
    "    'ipc_period_start', 'ipc_period_end',\n",
    "    'ar_period_start', 'ar_period_end',\n",
    "    # IPC classification data\n",
    "    'ipc_value', 'ipc_value_filled',\n",
    "    'ipc_binary_crisis', 'ipc_binary_crisis_filled',\n",
    "    # Other\n",
    "    'african_country_count',\n",
    "    # Fold for CV\n",
    "    'fold'\n",
    "]\n",
    "\n",
    "\n",
    "def load_dataset(file_path, name):\n",
    "    \"\"\"Load a feature dataset (parquet or CSV).\"\"\"\n",
    "    print(f\"\\n   Loading {name}...\")\n",
    "\n",
    "    parquet_path = file_path.with_suffix('.parquet')\n",
    "    if parquet_path.exists():\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "        print(f\"   Loaded from parquet: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "    else:\n",
    "        csv_path = file_path.with_suffix('.csv')\n",
    "        if csv_path.exists():\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"   Loaded from CSV: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Dataset not found: {file_path}\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca22def",
   "metadata": {},
   "source": [
    "## Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    ensure_directories()\n",
    "\n",
    "    print(f\"\\nStart time: {datetime.now()}\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # LOAD ALL DATASETS\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"LOADING FEATURE DATASETS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Base features from XGBoost Pipeline Phase 2\n",
    "    ratio_base = load_dataset(PHASE2_RESULTS / 'ratio_features_h8', 'Ratio features (base)')\n",
    "    zscore_base = load_dataset(PHASE2_RESULTS / 'zscore_features_h8', 'Zscore features (base)')\n",
    "\n",
    "    # HMM features from XGBoost Pipeline Phase 2\n",
    "    hmm_ratio = load_dataset(PHASE2_RESULTS / 'hmm_ratio_features_h8', 'HMM ratio features')\n",
    "    hmm_zscore = load_dataset(PHASE2_RESULTS / 'hmm_zscore_features_h8', 'HMM zscore features')\n",
    "\n",
    "    # DMD features from XGBoost Pipeline Phase 2\n",
    "    dmd_ratio = load_dataset(PHASE2_RESULTS / 'hmm_dmd_ratio_features_h8', 'DMD ratio features')\n",
    "    dmd_zscore = load_dataset(PHASE2_RESULTS / 'hmm_dmd_zscore_features_h8', 'DMD zscore features')\n",
    "\n",
    "    # ==========================================================================\n",
    "    # VERIFY COMMON KEY\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"Verifying common key...\")\n",
    "\n",
    "    key_cols = ['ipc_geographic_unit_full', 'year_month']\n",
    "\n",
    "    # Check all datasets have the key columns\n",
    "    for name, df in [('ratio_base', ratio_base), ('zscore_base', zscore_base),\n",
    "                     ('hmm_ratio', hmm_ratio), ('hmm_zscore', hmm_zscore),\n",
    "                     ('dmd_ratio', dmd_ratio), ('dmd_zscore', dmd_zscore)]:\n",
    "        missing = [col for col in key_cols if col not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"{name} missing key columns: {missing}\")\n",
    "\n",
    "    print(f\"   All datasets have key columns: {key_cols}\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # SELECT FEATURES FROM EACH DATASET\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"Selecting features from each dataset...\")\n",
    "\n",
    "    # Ratio base features (9 macro + location + metadata + target)\n",
    "    ratio_cols_to_keep = (\n",
    "        key_cols + RATIO_FEATURES + LOCATION_FEATURES +\n",
    "        TARGET_FEATURES + AR_FEATURES + IPC_FEATURES + METADATA_COLS\n",
    "    )\n",
    "    # Remove duplicates from ratio_cols_to_keep\n",
    "    ratio_cols_to_keep_unique = []\n",
    "    for col in ratio_cols_to_keep:\n",
    "        if col in ratio_base.columns and col not in ratio_cols_to_keep_unique:\n",
    "            ratio_cols_to_keep_unique.append(col)\n",
    "    ratio_selected = ratio_base[ratio_cols_to_keep_unique].copy()\n",
    "    # Also ensure no duplicate columns in ratio_selected itself\n",
    "    ratio_selected = ratio_selected.loc[:, ~ratio_selected.columns.duplicated()]\n",
    "    print(f\"   Ratio base: {len(ratio_selected.columns)} columns selected\")\n",
    "\n",
    "    # Zscore features (9 macro only - no keys, will merge on them)\n",
    "    zscore_cols_to_keep = ZSCORE_FEATURES\n",
    "    zscore_cols_to_keep = [c for c in zscore_cols_to_keep if c in zscore_base.columns]\n",
    "    zscore_selected = zscore_base[key_cols + zscore_cols_to_keep].copy()\n",
    "    print(f\"   Zscore base: {len(zscore_cols_to_keep)} feature columns selected\")\n",
    "\n",
    "    # HMM ratio features (6 features - no keys, will merge on them)\n",
    "    hmm_ratio_cols_to_keep = HMM_RATIO_FEATURES\n",
    "    hmm_ratio_cols_to_keep = [c for c in hmm_ratio_cols_to_keep if c in hmm_ratio.columns]\n",
    "    hmm_ratio_selected = hmm_ratio[key_cols + hmm_ratio_cols_to_keep].copy()\n",
    "    print(f\"   HMM ratio: {len(hmm_ratio_cols_to_keep)} feature columns selected\")\n",
    "\n",
    "    # HMM zscore features (6 features - no keys, will merge on them)\n",
    "    hmm_zscore_cols_to_keep = HMM_ZSCORE_FEATURES\n",
    "    hmm_zscore_cols_to_keep = [c for c in hmm_zscore_cols_to_keep if c in hmm_zscore.columns]\n",
    "    hmm_zscore_selected = hmm_zscore[key_cols + hmm_zscore_cols_to_keep].copy()\n",
    "    print(f\"   HMM zscore: {len(hmm_zscore_cols_to_keep)} feature columns selected\")\n",
    "\n",
    "    # DMD ratio features (6 features - no keys, will merge on them)\n",
    "    dmd_ratio_cols_to_keep = DMD_RATIO_FEATURES\n",
    "    dmd_ratio_cols_to_keep = [c for c in dmd_ratio_cols_to_keep if c in dmd_ratio.columns]\n",
    "    dmd_ratio_selected = dmd_ratio[key_cols + dmd_ratio_cols_to_keep].copy()\n",
    "    print(f\"   DMD ratio: {len(dmd_ratio_cols_to_keep)} feature columns selected\")\n",
    "\n",
    "    # DMD zscore features (6 features - no keys, will merge on them)\n",
    "    dmd_zscore_cols_to_keep = DMD_ZSCORE_FEATURES\n",
    "    dmd_zscore_cols_to_keep = [c for c in dmd_zscore_cols_to_keep if c in dmd_zscore.columns]\n",
    "    dmd_zscore_selected = dmd_zscore[key_cols + dmd_zscore_cols_to_keep].copy()\n",
    "    print(f\"   DMD zscore: {len(dmd_zscore_cols_to_keep)} feature columns selected\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # MERGE ALL DATASETS\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"Merging all feature datasets...\")\n",
    "\n",
    "    # Start with ratio features (has all metadata)\n",
    "    df_combined = ratio_selected.copy()\n",
    "    print(f\"   Starting with ratio base: {len(df_combined):,} rows\")\n",
    "\n",
    "    # Merge zscore features\n",
    "    df_combined = df_combined.merge(\n",
    "        zscore_selected,\n",
    "        on=key_cols,\n",
    "        how='left',\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "    print(f\"   After merging zscore: {len(df_combined):,} rows, {len(df_combined.columns)} columns\")\n",
    "\n",
    "    # Merge HMM ratio features\n",
    "    df_combined = df_combined.merge(\n",
    "        hmm_ratio_selected,\n",
    "        on=key_cols,\n",
    "        how='left',\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "    print(f\"   After merging HMM ratio: {len(df_combined):,} rows, {len(df_combined.columns)} columns\")\n",
    "\n",
    "    # Merge HMM zscore features\n",
    "    df_combined = df_combined.merge(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30169aab",
   "metadata": {},
   "source": [
    "## Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        hmm_zscore_selected,\n",
    "        on=key_cols,\n",
    "        how='left',\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "    print(f\"   After merging HMM zscore: {len(df_combined):,} rows, {len(df_combined.columns)} columns\")\n",
    "\n",
    "    # Merge DMD ratio features\n",
    "    df_combined = df_combined.merge(\n",
    "        dmd_ratio_selected,\n",
    "        on=key_cols,\n",
    "        how='left',\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "    print(f\"   After merging DMD ratio: {len(df_combined):,} rows, {len(df_combined.columns)} columns\")\n",
    "\n",
    "    # Merge DMD zscore features\n",
    "    df_combined = df_combined.merge(\n",
    "        dmd_zscore_selected,\n",
    "        on=key_cols,\n",
    "        how='left',\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "    print(f\"   After merging DMD zscore: {len(df_combined):,} rows, {len(df_combined.columns)} columns\")\n",
    "\n",
    "    # Remove duplicate columns (if any from merge)\n",
    "    dup_cols = [c for c in df_combined.columns if c.endswith('_dup')]\n",
    "    if dup_cols:\n",
    "        df_combined = df_combined.drop(columns=dup_cols)\n",
    "        print(f\"   Removed {len(dup_cols)} duplicate columns\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # ADD LOCATION ENCODING\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"Adding location encoding for XGBoost...\")\n",
    "\n",
    "    # Encode country and district for XGBoost\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    df_combined['country_encoded'] = LabelEncoder().fit_transform(df_combined['ipc_country'])\n",
    "    df_combined['district_encoded'] = LabelEncoder().fit_transform(df_combined['ipc_geographic_unit_full'])\n",
    "\n",
    "    print(f\"   Unique countries: {df_combined['country_encoded'].nunique()}\")\n",
    "    print(f\"   Unique districts: {df_combined['district_encoded'].nunique()}\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # FINAL FEATURE COUNT\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FEATURE COUNT SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    feature_counts = {\n",
    "        'Ratio macros': len([c for c in df_combined.columns if c.endswith('_ratio')]),\n",
    "        'Zscore macros': len([c for c in df_combined.columns if c.endswith('_zscore')]),\n",
    "        'HMM ratio': len([c for c in df_combined.columns if c.startswith('hmm_ratio_')]),\n",
    "        'HMM zscore': len([c for c in df_combined.columns if c.startswith('hmm_zscore_')]),\n",
    "        'DMD ratio': len([c for c in df_combined.columns if c.startswith('dmd_ratio_')]),\n",
    "        'DMD zscore': len([c for c in df_combined.columns if c.startswith('dmd_zscore_')]),\n",
    "        'Location': len([c for c in df_combined.columns if c in LOCATION_FEATURES]),\n",
    "        'Target': len([c for c in df_combined.columns if c in TARGET_FEATURES]),\n",
    "        'AR baseline': len([c for c in df_combined.columns if c in AR_FEATURES]),\n",
    "        'IPC': len([c for c in df_combined.columns if c in IPC_FEATURES]),\n",
    "        'Metadata': len([c for c in df_combined.columns if c in METADATA_COLS]),\n",
    "    }\n",
    "\n",
    "    for cat, count in feature_counts.items():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2da9b3",
   "metadata": {},
   "source": [
    "## Validation and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "        print(f\"   {cat:<15}: {count:>3} features\")\n",
    "\n",
    "    total_features = sum(feature_counts.values())\n",
    "    print(f\"\\n   TOTAL COLUMNS: {total_features}\")\n",
    "    print(f\"   TOTAL ROWS: {len(df_combined):,}\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # SAVE COMBINED DATASET\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"Saving combined HMM+DMD features...\")\n",
    "\n",
    "    # Parquet (preferred for large datasets)\n",
    "    output_parquet = PHASE3_OUTPUT / 'combined_advanced_features_h8.parquet'\n",
    "    df_combined.to_parquet(output_parquet, index=False)\n",
    "    print(f\"   Saved parquet: {output_parquet}\")\n",
    "\n",
    "    # CSV (for compatibility)\n",
    "    output_csv = PHASE3_OUTPUT / 'combined_advanced_features_h8.csv'\n",
    "    df_combined.to_csv(output_csv, index=False)\n",
    "    print(f\"   Saved CSV: {output_csv}\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # SAVE SUMMARY\n",
    "    # ==========================================================================\n",
    "    summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'phase': 'Phase 2: Combined HMM+DMD Features - XGBoost Pipeline',\n",
    "        'data': {\n",
    "            'total_observations': len(df_combined),\n",
    "            'total_features': total_features,\n",
    "            'feature_breakdown': feature_counts,\n",
    "            'n_countries': int(df_combined['ipc_country'].nunique()) if 'ipc_country' in df_combined.columns else 0,\n",
    "            'n_districts': int(df_combined['ipc_geographic_unit_full'].nunique()),\n",
    "        },\n",
    "        'feature_list': {\n",
    "            'ratio_macros': [c for c in df_combined.columns if c.endswith('_ratio')],\n",
    "            'zscore_macros': [c for c in df_combined.columns if c.endswith('_zscore')],\n",
    "            'hmm_ratio': [c for c in df_combined.columns if c.startswith('hmm_ratio_')],\n",
    "            'hmm_zscore': [c for c in df_combined.columns if c.startswith('hmm_zscore_')],\n",
    "            'dmd_ratio': [c for c in df_combined.columns if c.startswith('dmd_ratio_')],\n",
    "            'dmd_zscore': [c for c in df_combined.columns if c.startswith('dmd_zscore_')],\n",
    "        },\n",
    "        'outputs': {\n",
    "            'parquet': str(output_parquet),\n",
    "            'csv': str(output_csv),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    summary_path = PHASE3_OUTPUT / 'combined_advanced_summary.json'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"   Saved summary: {summary_path}\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 2 STEP 6 COMPLETE: COMBINED HMM+DMD FEATURES\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\n   Total features: {total_features}\")\n",
    "    print(f\"   Total observations: {len(df_combined):,}\")\n",
    "    print(f\"   Districts: {df_combined['ipc_geographic_unit_full'].nunique():,}\")\n",
    "    print(f\"\\n   Output files:\")\n",
    "    print(f\"   - {output_parquet}\")\n",
    "    print(f\"   - {output_csv}\")\n",
    "    print(f\"\\n   Next step: Phase 3 - XGBoost HMM+DMD Model Training\")\n",
    "    print(f\"\\nEnd time: {datetime.now()}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
