{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66882661",
   "metadata": {},
   "source": [
    "# Phase 2: HMM Ratio Features\n",
    "\n",
    "**Script**: `scripts\\04_stage2_feature_engineering\\phase2_feature_creation\\03_hmm_ratio_extraction.py`\n",
    "\n",
    "**Author**: Victor Collins Oppon, MSc Data Science, Middlesex University 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Extracts Hidden Markov Model states from ratio features.\n",
    "\n",
    "**KEY INSIGHT**: Captures latent regime changes in news dynamics.\n",
    "\n",
    "Trains separate HMM per district on ratio time series.\n",
    "\n",
    "**Runtime**: See script header for details\n",
    "\n",
    "**Input/Output**: See script header for file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c67eb0",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HMM Ratio Features - XGBoost Pipeline (REDESIGNED)\n",
    "====================================================\n",
    "Phase 2, Step 3b: Apply Hidden Markov Models to ratio features to identify latent narrative regimes.\n",
    "\n",
    "REDESIGN (December 24, 2025):\n",
    "- Binary regime: Pre-Crisis (0) vs Crisis-Prone (1)\n",
    "- 4 core input features: food_security, conflict, economic, weather\n",
    "- 3 output features: crisis_prob, transition_risk, entropy\n",
    "- Asymmetric transitions: Crisis persistence constraint (P(Crisis→Crisis) > 0.85)\n",
    "- District-level pooling: 1,322 separate HMMs (reduced parameters per model)\n",
    "\n",
    "RESEARCH PROPOSAL ALIGNMENT:\n",
    "\"Apply Hidden Markov Models (HMM) to the sequence of macro-category ratios\n",
    "to identify latent regimes aligned with IPC Phase 3 crisis threshold.\"\n",
    "\n",
    "Features Created:\n",
    "- hmm_ratio_crisis_prob: P(state=Crisis-Prone)\n",
    "- hmm_ratio_transition_risk: P(next_state=Crisis | current_state)\n",
    "- hmm_ratio_entropy: state uncertainty\n",
    "\n",
    "Author: Victor Collins Oppon, Claude Code\n",
    "Date: December 2025 (Redesigned: Dec 24, 2025)\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for config import\n",
    "sys.path.append(str(Path(__file__).parent.parent.parent))\n",
    "\n",
    "# Import from config\n",
    "from config import (\n",
    "    BASE_DIR,\n",
    "    STAGE1_DATA_DIR,\n",
    "    STAGE1_RESULTS_DIR,\n",
    "    STAGE2_DATA_DIR,\n",
    "    STAGE2_FEATURES_DIR,\n",
    "    STAGE2_MODELS_DIR,\n",
    "    FIGURES_DIR,\n",
    "    RANDOM_STATE,\n",
    "    FEATURE_CONFIG\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from hmmlearn import hmm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129d3510",
   "metadata": {},
   "source": [
    "## Load Ratio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define Phase 2 output directory\n",
    "PHASE2_RESULTS = STAGE2_FEATURES_DIR / 'phase2_features'\n",
    "PHASE2_RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ensure_directories():\n",
    "    \"\"\"Ensure output directories exist.\"\"\"\n",
    "    PHASE2_RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"XGBOOST PIPELINE - PHASE 2: HMM RATIO FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# HMM Parameters (from config)\n",
    "N_STATES = FEATURE_CONFIG['hmm_n_states']  # 2 states (redesigned)\n",
    "MIN_SEQUENCE_LENGTH = FEATURE_CONFIG['hmm_min_sequence_length']\n",
    "ROLLING_WINDOW = FEATURE_CONFIG['hmm_rolling_window']\n",
    "HMM_INPUT_FEATURES = FEATURE_CONFIG['hmm_input_features']  # 4 core features\n",
    "HMM_OUTPUT_FEATURES = FEATURE_CONFIG['hmm_output_features']  # 3 outputs\n",
    "CRISIS_PERSISTENCE_MIN = FEATURE_CONFIG['hmm_crisis_persistence_min']  # 0.85\n",
    "\n",
    "print(f\"HMM Configuration (REDESIGNED):\")\n",
    "print(f\"  N_STATES: {N_STATES} (Binary regime: Pre-Crisis vs Crisis-Prone)\")\n",
    "print(f\"  INPUT_FEATURES: {HMM_INPUT_FEATURES}\")\n",
    "print(f\"  OUTPUT_FEATURES: {HMM_OUTPUT_FEATURES}\")\n",
    "print(f\"  MIN_SEQUENCE_LENGTH: {MIN_SEQUENCE_LENGTH} months\")\n",
    "print(f\"  ROLLING_WINDOW: {ROLLING_WINDOW} months\")\n",
    "print(f\"  CRISIS_PERSISTENCE: >={CRISIS_PERSISTENCE_MIN} (asymmetric transitions)\")\n",
    "\n",
    "# REDESIGNED: Only 4 core ratio features (no deltas/trends - HMM models dynamics natively)\n",
    "HMM_RATIO_FEATURES = HMM_INPUT_FEATURES  # ['food_security_ratio', 'conflict_ratio', 'economic_ratio', 'weather_ratio']\n",
    "\n",
    "\n",
    "def load_ratio_features():\n",
    "    \"\"\"Load ratio features from Phase 2.\"\"\"\n",
    "    print(\"\\n   Loading ratio features...\")\n",
    "\n",
    "    ratio_file = PHASE2_RESULTS / 'ratio_features_h8.parquet'\n",
    "    if ratio_file.exists():\n",
    "        df = pd.read_parquet(ratio_file)\n",
    "    else:\n",
    "        csv_file = PHASE2_RESULTS / 'ratio_features_h8.csv'\n",
    "        if csv_file.exists():\n",
    "            df = pd.read_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0190a60",
   "metadata": {},
   "source": [
    "## HMM Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "        else:\n",
    "            raise FileNotFoundError(\"Ratio features not found. Run 01_ratio_feature_engineering.py first.\")\n",
    "\n",
    "    print(f\"   Loaded {len(df):,} observations\")\n",
    "\n",
    "    # FORCE use of canonical district identifier\n",
    "    district_col = 'ipc_geographic_unit_full'\n",
    "    if district_col not in df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Required column '{district_col}' not found in data. \"\n",
    "            f\"Available columns: {df.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "    # Sort by district and time\n",
    "    df = df.sort_values([district_col, 'year_month']).reset_index(drop=True)\n",
    "\n",
    "    return df, district_col\n",
    "\n",
    "\n",
    "def fit_hmm(X, n_states=2, random_state=42):\n",
    "    \"\"\"Fit Gaussian HMM to observation sequence with asymmetric transition constraint.\n",
    "\n",
    "    REDESIGN: Binary regime (Pre-Crisis=0, Crisis-Prone=1) with crisis persistence.\n",
    "    \"\"\"\n",
    "    if len(X) < MIN_SEQUENCE_LENGTH:\n",
    "        return None\n",
    "\n",
    "    # Handle missing values\n",
    "    col_means = np.nanmean(X, axis=0)\n",
    "    for j in range(X.shape[1]):\n",
    "        mask = np.isnan(X[:, j])\n",
    "        X[mask, j] = col_means[j] if not np.isnan(col_means[j]) else 0\n",
    "\n",
    "    # Handle constant features\n",
    "    feature_stds = np.std(X, axis=0)\n",
    "    for j in range(X.shape[1]):\n",
    "        if feature_stds[j] == 0:\n",
    "            X[:, j] = X[:, j] + np.random.randn(len(X)) * 0.01\n",
    "\n",
    "    try:\n",
    "        model = hmm.GaussianHMM(\n",
    "            n_components=n_states,\n",
    "            covariance_type='diag',\n",
    "            n_iter=300,  # IMPROVED: Increased from 100 to 300 for better convergence\n",
    "            tol=1e-3,    # IMPROVED: Explicit tolerance threshold\n",
    "            random_state=random_state,\n",
    "            init_params='stmc',  # IMPROVED: Initialize starts/transitions/means/covariances\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # REDESIGN: Initialize asymmetric transition matrix\n",
    "        # State 0 (Pre-Crisis): Can transition to Crisis\n",
    "        # State 1 (Crisis-Prone): High persistence (asset depletion irreversibility)\n",
    "        if n_states == 2:\n",
    "            model.transmat_ = np.array([\n",
    "                [0.80, 0.20],  # Pre-Crisis: 80% stay, 20% worsen\n",
    "                [0.10, 0.90]   # Crisis: 10% recover, 90% persist\n",
    "            ])\n",
    "\n",
    "        model.fit(X)\n",
    "\n",
    "        # Enforce crisis persistence constraint after fitting\n",
    "        if n_states == 2 and model.transmat_[1, 1] < CRISIS_PERSISTENCE_MIN:\n",
    "            # Adjust transition matrix to meet constraint\n",
    "            recovery_prob = 1 - CRISIS_PERSISTENCE_MIN\n",
    "            model.transmat_[1, :] = [recovery_prob, CRISIS_PERSISTENCE_MIN]\n",
    "\n",
    "        hidden_states = model.predict(X)\n",
    "        state_probs = model.predict_proba(X)\n",
    "        transition_matrix = model.transmat_\n",
    "\n",
    "        return {\n",
    "            'hidden_states': hidden_states,\n",
    "            'state_probs': state_probs,\n",
    "            'transition_matrix': transition_matrix,\n",
    "            'converged': model.monitor_.converged,\n",
    "            'n_iter': model.monitor_.iter\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def order_states_by_ipc(hmm_result, ipc_values):\n",
    "    \"\"\"Order HMM states based on IPC outcomes (supervised labeling).\n",
    "\n",
    "    CORRECTED (Dec 24, 2025): ipc_values should be lag-1 only (length = len(hidden_states) - 1)\n",
    "    to prevent data leakage. We use historical IPC to label states, excluding current time.\n",
    "    \"\"\"\n",
    "    hidden_states = hmm_result['hidden_states']\n",
    "    state_probs = hmm_result['state_probs']\n",
    "\n",
    "    # CRITICAL FIX: Use lag-1 IPC only (exclude current time to prevent leakage)\n",
    "    # ipc_values has length = len(hidden_states) - 1\n",
    "    # We use historical states (excluding last) for state ordering\n",
    "    historical_states = hidden_states[:-1]  # Exclude current time state\n",
    "\n",
    "    state_ipc_means = []\n",
    "    for s in range(N_STATES):\n",
    "        state_mask = historical_states == s\n",
    "        valid_ipc = ipc_values[state_mask]\n",
    "        valid_ipc = valid_ipc[~np.isnan(valid_ipc)]\n",
    "\n",
    "        if len(valid_ipc) > 0:\n",
    "            mean_ipc = np.mean(valid_ipc)\n",
    "        else:\n",
    "            mean_ipc = 0\n",
    "        state_ipc_means.append((s, mean_ipc))\n",
    "\n",
    "    state_order = sorted(state_ipc_means, key=lambda x: x[1])\n",
    "    old_to_new = {old: new for new, (old, _) in enumerate(state_order)}\n",
    "\n",
    "    new_hidden_states = np.array([old_to_new[s] for s in hidden_states])\n",
    "\n",
    "    new_state_probs = np.zeros_like(state_probs)\n",
    "    for old, new in old_to_new.items():\n",
    "        new_state_probs[:, new] = state_probs[:, old]\n",
    "\n",
    "    trans = hmm_result['transition_matrix']\n",
    "    new_trans = np.zeros_like(trans)\n",
    "    for old_from, new_from in old_to_new.items():\n",
    "        for old_to, new_to in old_to_new.items():\n",
    "            new_trans[new_from, new_to] = trans[old_from, old_to]\n",
    "\n",
    "    return new_hidden_states, new_state_probs, new_trans\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e941d9",
   "metadata": {},
   "source": [
    "## Process All Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25430ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_transition_risk(state_probs, transition_matrix, crisis_state=1):\n",
    "    \"\"\"Compute probability of transitioning to crisis state.\n",
    "\n",
    "    REDESIGN: Binary states, so crisis_state=1 (Crisis-Prone).\n",
    "    \"\"\"\n",
    "    transition_risk = np.zeros(len(state_probs))\n",
    "\n",
    "    for t in range(len(state_probs)):\n",
    "        for s in range(N_STATES):\n",
    "            transition_risk[t] += state_probs[t, s] * transition_matrix[s, crisis_state]\n",
    "\n",
    "    return transition_risk\n",
    "\n",
    "\n",
    "def compute_entropy(state_probs):\n",
    "    \"\"\"Compute entropy of state distribution.\"\"\"\n",
    "    eps = 1e-10\n",
    "    entropy = -np.sum(state_probs * np.log(state_probs + eps), axis=1)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def extract_hmm_features_for_window(X_window, ipc_window):\n",
    "    \"\"\"Extract HMM features for a single rolling window.\n",
    "\n",
    "    REDESIGN: Only 3 outputs (crisis_prob, transition_risk, entropy).\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'hmm_ratio_crisis_prob': np.nan,\n",
    "        'hmm_ratio_transition_risk': np.nan,\n",
    "        'hmm_ratio_entropy': np.nan,\n",
    "        'hmm_ratio_converged': 0\n",
    "    }\n",
    "\n",
    "    if len(X_window) < MIN_SEQUENCE_LENGTH:\n",
    "        return features\n",
    "\n",
    "    hmm_result = fit_hmm(X_window.copy(), n_states=N_STATES, random_state=RANDOM_STATE)\n",
    "\n",
    "    if hmm_result is None:\n",
    "        return features\n",
    "\n",
    "    try:\n",
    "        hidden_states, state_probs, trans_matrix = order_states_by_ipc(\n",
    "            hmm_result, ipc_window\n",
    "        )\n",
    "    except:\n",
    "        return features\n",
    "\n",
    "    transition_risk = compute_transition_risk(state_probs, trans_matrix, crisis_state=1)  # Binary: crisis=1\n",
    "    entropy = compute_entropy(state_probs)\n",
    "\n",
    "    last_idx = len(hidden_states) - 1\n",
    "    # REDESIGN: Only 3 features\n",
    "    # crisis_prob = P(Crisis-Prone state) = state_probs[:, 1]\n",
    "    features['hmm_ratio_crisis_prob'] = state_probs[last_idx, 1]  # State 1 = Crisis-Prone\n",
    "    features['hmm_ratio_transition_risk'] = transition_risk[last_idx]\n",
    "    features['hmm_ratio_entropy'] = entropy[last_idx]\n",
    "    features['hmm_ratio_converged'] = int(hmm_result['converged'])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_hmm_features(df, district_col):\n",
    "    \"\"\"Extract HMM features for all districts using rolling windows.\n",
    "\n",
    "    REDESIGN: Only 3 output features (crisis_prob, transition_risk, entropy).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"Extracting HMM ratio features (rolling window, REDESIGNED)...\")\n",
    "    print(f\"   Window size: {ROLLING_WINDOW} months\")\n",
    "\n",
    "    available_features = [f for f in HMM_RATIO_FEATURES if f in df.columns]\n",
    "    print(f\"   Using {len(available_features)} core features for HMM (REDESIGNED)\")\n",
    "    print(f\"   Features: {available_features}\")\n",
    "\n",
    "    if len(available_features) == 0:\n",
    "        print(\"   ERROR: No HMM ratio features found!\")\n",
    "        return df\n",
    "\n",
    "    # REDESIGN: Initialize only 3 output columns\n",
    "    df['hmm_ratio_crisis_prob'] = np.nan\n",
    "    df['hmm_ratio_transition_risk'] = np.nan\n",
    "    df['hmm_ratio_entropy'] = np.nan\n",
    "    df['hmm_ratio_converged'] = 0\n",
    "\n",
    "    districts = df[district_col].unique()\n",
    "    n_districts = len(districts)\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    convergence_fail_count = 0\n",
    "\n",
    "    for i, district in enumerate(districts):\n",
    "        if (i + 1) % 200 == 0 or i == 0:\n",
    "            print(f\"   Processing district {i+1}/{n_districts}... (convergence failures: {convergence_fail_count})\", flush=True)\n",
    "\n",
    "        district_mask = df[district_col] == district\n",
    "        district_data = df.loc[district_mask].copy()\n",
    "\n",
    "        if len(district_data) < MIN_SEQUENCE_LENGTH:\n",
    "            fail_count += 1\n",
    "            continue\n",
    "\n",
    "        district_data = district_data.sort_values('year_month')\n",
    "        district_idx = district_data.index.tolist()\n",
    "\n",
    "        X_full = district_data[available_features].values\n",
    "\n",
    "        ipc_col = 'ipc_value_filled' if 'ipc_value_filled' in district_data.columns else 'ipc_value'\n",
    "        if ipc_col in district_data.columns:\n",
    "            ipc_full = district_data[ipc_col].values\n",
    "        else:\n",
    "            ipc_full = np.zeros(len(X_full))\n",
    "\n",
    "        district_success = False\n",
    "\n",
    "        for t_idx in range(MIN_SEQUENCE_LENGTH - 1, len(district_data)):\n",
    "            start_idx = max(0, t_idx - ROLLING_WINDOW + 1)\n",
    "\n",
    "            # DATA LEAKAGE FIX (December 24, 2025):\n",
    "            # Use rolling window including current time for HMM fitting (OK - uses only GDELT features)\n",
    "            X_window = X_full[start_idx:t_idx + 1, :]\n",
    "\n",
    "            # CRITICAL FIX: Exclude current IPC from state ordering to prevent leakage\n",
    "            # IPC window must use LAG-1 ONLY (exclude current time t)\n",
    "            # Otherwise, current IPC value influences how we label states → circular dependency\n",
    "            # At prediction time, we won't have current IPC, so states would be mislabeled\n",
    "            ipc_window = ipc_full[start_idx:t_idx]  # CORRECTED: Exclude current time (lag-1 only)\n",
    "\n",
    "            if len(X_window) >= MIN_SEQUENCE_LENGTH:\n",
    "                features = extract_hmm_features_for_window(X_window, ipc_window)\n",
    "\n",
    "                current_idx = district_idx[t_idx]\n",
    "                # REDESIGN: Only 3 features\n",
    "                df.loc[current_idx, 'hmm_ratio_crisis_prob'] = features['hmm_ratio_crisis_prob']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46badd43",
   "metadata": {},
   "source": [
    "## Validation and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "                df.loc[current_idx, 'hmm_ratio_transition_risk'] = features['hmm_ratio_transition_risk']\n",
    "                df.loc[current_idx, 'hmm_ratio_entropy'] = features['hmm_ratio_entropy']\n",
    "                df.loc[current_idx, 'hmm_ratio_converged'] = features['hmm_ratio_converged']\n",
    "\n",
    "                if not np.isnan(features['hmm_ratio_crisis_prob']):\n",
    "                    district_success = True\n",
    "\n",
    "                # Track convergence failures\n",
    "                if features['hmm_ratio_converged'] == 0:\n",
    "                    convergence_fail_count += 1\n",
    "\n",
    "        if district_success:\n",
    "            success_count += 1\n",
    "        else:\n",
    "            fail_count += 1\n",
    "\n",
    "    print(f\"\\n   HMM ratio extraction complete:\")\n",
    "    print(f\"   Successful: {success_count:,} districts\")\n",
    "    print(f\"   Failed: {fail_count:,} districts\")\n",
    "    print(f\"   Coverage: {100 * success_count / n_districts:.1f}%\")\n",
    "    print(f\"   Convergence failures: {convergence_fail_count:,} observations\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    ensure_directories()\n",
    "\n",
    "    print(f\"\\nStart time: {datetime.now()}\")\n",
    "\n",
    "    # Load ratio features\n",
    "    df, district_col = load_ratio_features()\n",
    "\n",
    "    # Extract HMM features\n",
    "    df = extract_hmm_features(df, district_col)\n",
    "\n",
    "    # Save features\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"Saving HMM ratio features...\")\n",
    "\n",
    "    output_path = PHASE2_RESULTS / 'hmm_ratio_features_h8.parquet'\n",
    "    df.to_parquet(output_path, index=False)\n",
    "    print(f\"   Saved: {output_path}\")\n",
    "\n",
    "    csv_path = PHASE2_RESULTS / 'hmm_ratio_features_h8.csv'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"   Saved: {csv_path}\")\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"HMM RATIO FEATURE SUMMARY (REDESIGNED)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # REDESIGN: Only 3 output features\n",
    "    hmm_cols = ['hmm_ratio_crisis_prob', 'hmm_ratio_transition_risk', 'hmm_ratio_entropy']\n",
    "    for col in hmm_cols:\n",
    "        if col in df.columns:\n",
    "            valid = df[col].notna().sum()\n",
    "            mean_val = df[col].mean()\n",
    "            std_val = df[col].std()\n",
    "            print(f\"   {col}: {valid:,} valid, mean={mean_val:.4f}, std={std_val:.4f}\")\n",
    "\n",
    "    converged_count = df['hmm_ratio_converged'].sum()\n",
    "    total_obs = len(df)\n",
    "    print(f\"\\n   Convergence: {converged_count:,} / {total_obs:,} ({100*converged_count/total_obs:.1f}%)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 2 STEP 3b COMPLETE: HMM Ratio Features (REDESIGNED)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"End time: {datetime.now()}\")\n",
    "    print(f\"\\nREDESIGN SUMMARY:\")\n",
    "    print(f\"  - States: 2 (Pre-Crisis vs Crisis-Prone)\")\n",
    "    print(f\"  - Input features: {len(HMM_RATIO_FEATURES)} core categories\")\n",
    "    print(f\"  - Output features: {len(HMM_OUTPUT_FEATURES)} (75% reduction from 12)\")\n",
    "    print(f\"  - Asymmetric transitions: Crisis persistence >= {CRISIS_PERSISTENCE_MIN}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
